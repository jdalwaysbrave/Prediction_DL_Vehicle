{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)  # 关闭科学计数法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_csv = pd.read_csv(\"./filtered.csv\")#读取filtered file\n",
    "trajectory = np.array(data_csv, dtype=np.float64)  # trajectory1[:, 2:9] 原为2个数据 现为8个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataX shape: (2408, 10, 5)\n",
      "dataY shape: (2408, 2)\n",
      "dataX shape: (2408, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = [], []\n",
    "    # 定义滑动窗口的大小和步长\n",
    "window_size = 10\n",
    "step_size = 1\n",
    "\n",
    " # 创建输入数据和目标数据\n",
    "\n",
    "    # 创建输入数据和目标数据\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(trajectory) - window_size, step_size):\n",
    "    dataX.append(trajectory[i:i+window_size])\n",
    "    dataY.append(trajectory[i+window_size,1:3])\n",
    "\n",
    " # 将输入数据和目标数据转换为numpy数组\n",
    "dataX = np.array(dataX, dtype='float64')\n",
    "dataY = np.array(dataY, dtype='float64')\n",
    "# dataY = dataY.reshape(2408,1,2)\n",
    "print('dataX shape:', dataX.shape) # (91, 10, 3)\n",
    "print('dataY shape:', dataY.shape) # (91, 2)\n",
    "# 使用transpose()方法交换第二维度和第三维度\n",
    "dataX = dataX.transpose((0, 2, 1))\n",
    "print('dataX shape:', dataX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance based on haversine and time difference\n",
    "# convert time to seconds\n",
    "\n",
    "train_x = dataX\n",
    "train_y= dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[     0.          1.          2.     ...      7.          8.\n",
      "        9.    ]\n",
      "  [679864.4007 679864.4159 679864.4315 ... 679864.5083 679864.5238\n",
      "   679864.5391]\n",
      "  [419283.8057 419284.144  419284.4826 ... 419286.1755 419286.5141\n",
      "   419286.8528]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     1.          2.          3.     ...      8.          9.\n",
      "       10.    ]\n",
      "  [679864.4159 679864.4315 679864.4467 ... 679864.5238 679864.5391\n",
      "   679864.5546]\n",
      "  [419284.144  419284.4826 419284.8213 ... 419286.5141 419286.8528\n",
      "   419287.1914]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     2.          3.          4.     ...      9.         10.\n",
      "       11.    ]\n",
      "  [679864.4315 679864.4467 679864.4623 ... 679864.5391 679864.5546\n",
      "   679864.5699]\n",
      "  [419284.4826 419284.8213 419285.1599 ... 419286.8528 419287.1914\n",
      "   419287.53  ]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  2405.       2406.       2407.     ...   2412.       2413.\n",
      "     2414.    ]\n",
      "  [679949.3305 679949.1406 679948.9507 ... 679948.0009 679947.811\n",
      "   679947.6212]\n",
      "  [419863.8233 419864.646  419865.4683 ... 419869.581  419870.4036\n",
      "   419871.226 ]\n",
      "  [    27.74       27.7        27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.38       -0.19        0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2406.       2407.       2408.     ...   2413.       2414.\n",
      "     2415.    ]\n",
      "  [679949.1406 679948.9507 679948.7608 ... 679947.811  679947.6212\n",
      "   679947.4313]\n",
      "  [419864.646  419865.4683 419866.291  ... 419870.4036 419871.226\n",
      "   419872.0486]\n",
      "  [    27.7        27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.19        0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2407.       2408.       2409.     ...   2414.       2415.\n",
      "     2416.    ]\n",
      "  [679948.9507 679948.7608 679948.5709 ... 679947.6212 679947.4313\n",
      "   679947.2414]\n",
      "  [419865.4683 419866.291  419867.1133 ... 419871.226  419872.0486\n",
      "   419872.871 ]\n",
      "  [    27.69       27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]]\n",
      "[[679864.5546 419287.1914]\n",
      " [679864.5699 419287.53  ]\n",
      " [679864.5854 419287.8687]\n",
      " ...\n",
      " [679947.4313 419872.0486]\n",
      " [679947.2414 419872.871 ]\n",
      " [679947.0515 419873.6937]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408, 5, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# convert pandas dataframe to numpy array\n",
    "\n",
    "x_data = train_x\n",
    "x_data = np.array(x_data)\n",
    "# x_data = x_data.reshape(19828,5,1)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Too Much Slow Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = train_y\n",
    "\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape : (2408, 50)\n",
      "new X_data shape : (2408, 5, 10)\n",
      "y_data shape : (2408, 2)\n",
      "new y_data shape : (2408, 2)\n",
      "[[-1.         -1.        ]\n",
      " [-0.99969315 -0.99884536]\n",
      " [-0.99938229 -0.99769038]\n",
      " ...\n",
      " [ 0.66212312  0.99439013]\n",
      " [ 0.65831461  0.99719455]\n",
      " [ 0.65450609  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Preporcessing Normalizing Valuse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "# new_df= x_data.reshape(x_data.shape[0],5)\n",
    "x_data=x_data.reshape(2408,50)\n",
    "new_x_data = sc.fit_transform(x_data)\n",
    "new_x_data = new_x_data.reshape(2408,5,10)\n",
    "\n",
    "print('X_data shape :', x_data.shape)\n",
    "print('new X_data shape :', new_x_data.shape)\n",
    "\n",
    "\n",
    "# y_data=y_data.reshape(2408,2)\n",
    "new_y_data = sc.fit_transform(y_data)\n",
    "# new_y_data = new_y_data.reshape(2408,2)\n",
    "print('y_data shape :', y_data.shape)\n",
    "print('new y_data shape :', new_y_data.shape)\n",
    "# print(new_x_data)\n",
    "print(new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM,RNN\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(new_x_data, new_y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1685, 5, 10)\n",
      "(1685, 2)\n",
      "(723, 5, 10)\n",
      "(723, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Embedding, LSTM, Dropout, Activation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import GRU, lambda, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 32)                4224      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# LSTM层的units数：增加units数可以增加模型的表达能力，但也会增加模型的复杂度和训练时间。因此，可以尝试不同的units数并找到一个合适的值。\\n\\n# Dropout层的比率：增加Dropout比率可以减少过拟合的风险，但过高的Dropout比率会影响模型的性能。因此，可以尝试不同的Dropout比率并找到一个合适的值。\\n\\n# 学习率(learning rate)：Adam优化器默认的学习率通常可以正常工作，但有时候需要手动调整学习率以加速或稳定训练过程。\\n\\n# 批量大小(batch size)：批量大小会影响模型的训练速度和内存占用情况。通常情况下，使用大批量大小可以加快训练速度，但也会占用更多的内存。\\n\\n# 训练轮数(epochs)：增加训练轮数可以提高模型的精度，但也会增加训练时间。可以使用早停法(early stopping)等技术来提高模型的训练效率。\\n '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# hidden_size=64  #较小的 hidden_size，比如 64、128 或 256 等。而对于一些较为复杂的任务，比如机器翻译、语音识别等，可能需要使用更大的 hidden_size，比如 512、1024 或更大的值\n",
    "\n",
    "# model.add(GRU(hidden_size, input_shape=(5,10), return_sequences=True))\n",
    "# model.add(Lambda(lambda x: x[:, -1, :]))\n",
    "# model.add(Dense(2))\n",
    "\n",
    "#     # 编译模型\n",
    "# model.compile(optimizer='Adam', loss='mse')\n",
    "# import tensorflow as tf\n",
    "\n",
    "# 创建GRU模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=32, input_shape=(5,10)),\n",
    "    tf.keras.layers.Dense(units=2),\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "'''\n",
    "# LSTM层的units数：增加units数可以增加模型的表达能力，但也会增加模型的复杂度和训练时间。因此，可以尝试不同的units数并找到一个合适的值。\n",
    "\n",
    "# Dropout层的比率：增加Dropout比率可以减少过拟合的风险，但过高的Dropout比率会影响模型的性能。因此，可以尝试不同的Dropout比率并找到一个合适的值。\n",
    "\n",
    "# 学习率(learning rate)：Adam优化器默认的学习率通常可以正常工作，但有时候需要手动调整学习率以加速或稳定训练过程。\n",
    "\n",
    "# 批量大小(batch size)：批量大小会影响模型的训练速度和内存占用情况。通常情况下，使用大批量大小可以加快训练速度，但也会占用更多的内存。\n",
    "\n",
    "# 训练轮数(epochs)：增加训练轮数可以提高模型的精度，但也会增加训练时间。可以使用早停法(early stopping)等技术来提高模型的训练效率。\n",
    " '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 3s 11ms/step - loss: 0.1716 - val_loss: 0.0492\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0305 - val_loss: 0.0170\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0107\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0070 - val_loss: 0.0065\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0058\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.4227e-04 - val_loss: 9.9861e-04\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.5975e-04 - val_loss: 8.9102e-04\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9430e-04 - val_loss: 8.2820e-04\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2397e-04 - val_loss: 7.7006e-04\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.8092e-04 - val_loss: 7.2472e-04\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3821e-04 - val_loss: 7.0842e-04\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.1788e-04 - val_loss: 6.6249e-04\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3239e-04 - val_loss: 6.3913e-04\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.6795e-04 - val_loss: 6.2330e-04\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4550e-04 - val_loss: 6.1530e-04\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.2061e-04 - val_loss: 5.7538e-04\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8925e-04 - val_loss: 5.5368e-04\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8051e-04 - val_loss: 5.2994e-04\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5568e-04 - val_loss: 4.9365e-04\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3635e-04 - val_loss: 4.8826e-04\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.2802e-04 - val_loss: 4.4836e-04\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1193e-04 - val_loss: 4.5382e-04\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9070e-04 - val_loss: 4.5130e-04\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7205e-04 - val_loss: 4.0771e-04\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6562e-04 - val_loss: 3.9301e-04\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.6100e-04 - val_loss: 3.6957e-04\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3304e-04 - val_loss: 3.6309e-04\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2124e-04 - val_loss: 3.6136e-04\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1403e-04 - val_loss: 3.4621e-04\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.0534e-04 - val_loss: 3.1592e-04\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 2.8529e-04 - val_loss: 3.4769e-04\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.8089e-04 - val_loss: 3.1549e-04\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.6700e-04 - val_loss: 3.7763e-04\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.6492e-04 - val_loss: 2.9589e-04\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.5109e-04 - val_loss: 2.7349e-04\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.2930e-04 - val_loss: 2.4938e-04\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3815e-04 - val_loss: 2.5188e-04\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.0862e-04 - val_loss: 2.4884e-04\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9548e-04 - val_loss: 2.4862e-04\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9803e-04 - val_loss: 2.5178e-04\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.8513e-04 - val_loss: 2.1137e-04\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.7895e-04 - val_loss: 2.1031e-04\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.8112e-04 - val_loss: 2.7678e-04\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.7549e-04 - val_loss: 2.1495e-04\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.5896e-04 - val_loss: 1.8532e-04\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.4724e-04 - val_loss: 1.9196e-04\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.4351e-04 - val_loss: 2.2607e-04\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.4014e-04 - val_loss: 1.7736e-04\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.3701e-04 - val_loss: 1.7700e-04\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.2343e-04 - val_loss: 1.9222e-04\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.2823e-04 - val_loss: 1.6103e-04\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.1510e-04 - val_loss: 1.6219e-04\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.2431e-04 - val_loss: 1.5270e-04\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.0408e-04 - val_loss: 1.4061e-04\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.1199e-04 - val_loss: 1.4764e-04\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.0074e-04 - val_loss: 1.3570e-04\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.0914e-04 - val_loss: 1.7487e-04\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.0367e-04 - val_loss: 1.5320e-04\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9955e-05 - val_loss: 1.3339e-04\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 1.0736e-04 - val_loss: 1.3152e-04\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.3286e-05 - val_loss: 1.3049e-04\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.0820e-04 - val_loss: 1.2979e-04\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.2165e-05 - val_loss: 1.5102e-04\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4349e-05 - val_loss: 1.1378e-04\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.4164e-05 - val_loss: 1.1815e-04\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.6985e-05 - val_loss: 1.0925e-04\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.9501e-05 - val_loss: 1.0417e-04\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.3236e-05 - val_loss: 1.0773e-04\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.2950e-05 - val_loss: 1.0251e-04\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 7.5098e-05 - val_loss: 1.0816e-04\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0201e-05 - val_loss: 9.6024e-05\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.1207e-05 - val_loss: 1.0450e-04\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.8989e-05 - val_loss: 1.0613e-04\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.0689e-05 - val_loss: 1.0167e-04\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7779e-05 - val_loss: 1.1931e-04\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 6.6264e-05 - val_loss: 1.3002e-04\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 8.1573e-05 - val_loss: 9.6912e-05\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7845e-05 - val_loss: 7.9737e-05\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.8480e-05 - val_loss: 8.3025e-05\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.4339e-05 - val_loss: 8.6096e-05\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4358e-05 - val_loss: 9.0420e-05\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.4072e-05 - val_loss: 1.0684e-04\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.2073e-05 - val_loss: 7.6060e-05\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.7783e-05 - val_loss: 7.6759e-05\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4514e-05 - val_loss: 1.0135e-04\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.3734e-05 - val_loss: 7.6613e-05\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1666e-05 - val_loss: 7.4904e-05\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.7554e-05 - val_loss: 7.8170e-05\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8812e-05 - val_loss: 6.7267e-05\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.8153e-05 - val_loss: 7.1007e-05\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1624e-05 - val_loss: 6.8606e-05\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7313e-05 - val_loss: 1.0720e-04\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.0894e-05 - val_loss: 6.6343e-05\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3798e-05 - val_loss: 6.9754e-05\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6935e-05 - val_loss: 6.6617e-05\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3900e-05 - val_loss: 7.5792e-05\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.0554e-05 - val_loss: 9.8493e-05\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 5.3496e-05 - val_loss: 6.1890e-05\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4562e-05 - val_loss: 6.3930e-05\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3865e-05 - val_loss: 6.5495e-05\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.0635e-05 - val_loss: 6.3345e-05\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.4296e-05 - val_loss: 5.7906e-05\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6234e-05 - val_loss: 7.8050e-05\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1324e-05 - val_loss: 8.1600e-05\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6908e-05 - val_loss: 6.8996e-05\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8325e-05 - val_loss: 7.2200e-05\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7867e-05 - val_loss: 7.6315e-05\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.1843e-05 - val_loss: 6.2492e-05\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5235e-05 - val_loss: 5.9784e-05\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8395e-05 - val_loss: 6.1200e-05\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0786e-05 - val_loss: 6.1940e-05\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8015e-05 - val_loss: 5.6036e-05\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5854e-05 - val_loss: 6.9717e-05\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5513e-05 - val_loss: 5.3605e-05\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.0257e-05 - val_loss: 8.5324e-05\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.8039e-05 - val_loss: 5.7540e-05\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.9273e-05 - val_loss: 5.2157e-05\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5070e-05 - val_loss: 6.4536e-05\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1380e-05 - val_loss: 5.4690e-05\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.4875e-05 - val_loss: 5.5812e-05\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.4059e-05 - val_loss: 6.5129e-05\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2109e-05 - val_loss: 5.7499e-05\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9393e-05 - val_loss: 5.6495e-05\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.6722e-05 - val_loss: 9.0377e-05\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2184e-05 - val_loss: 4.5550e-05\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3730e-05 - val_loss: 6.3570e-05\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.9979e-05 - val_loss: 6.0853e-05\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1413e-05 - val_loss: 6.3957e-05\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2825e-05 - val_loss: 4.5050e-05\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.2541e-05 - val_loss: 5.0960e-05\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1982e-05 - val_loss: 5.9360e-05\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.3622e-05 - val_loss: 4.8673e-05\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3087e-05 - val_loss: 4.3016e-05\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3424e-05 - val_loss: 6.8074e-05\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2194e-05 - val_loss: 5.2181e-05\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.0849e-05 - val_loss: 5.8685e-05\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.5417e-05 - val_loss: 5.6252e-05\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 3.2425e-05 - val_loss: 7.3889e-05\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1394e-05 - val_loss: 4.2982e-05\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.0428e-05 - val_loss: 4.5971e-05\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.8043e-05 - val_loss: 4.7256e-05\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1589e-05 - val_loss: 3.8095e-05\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7488e-05 - val_loss: 8.9566e-05\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1620e-05 - val_loss: 4.3305e-05\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.4240e-05 - val_loss: 4.0839e-05\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.0662e-05 - val_loss: 4.9982e-05\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3974e-05 - val_loss: 6.5588e-05\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 0s 5ms/step - loss: 4.6416e-05 - val_loss: 5.9207e-05\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3394e-05 - val_loss: 5.9445e-05\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1187e-05 - val_loss: 3.9379e-05\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.5730e-05 - val_loss: 5.0051e-05\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3992e-05 - val_loss: 4.8052e-05\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7102e-05 - val_loss: 4.3095e-05\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3530e-05 - val_loss: 4.4962e-05\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.1009e-05 - val_loss: 4.4609e-05\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.2503e-05 - val_loss: 3.6183e-05\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.0133e-05 - val_loss: 6.3166e-05\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3651e-05 - val_loss: 6.0642e-05\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7457e-05 - val_loss: 4.2585e-05\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.1076e-05 - val_loss: 3.4269e-05\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7689e-05 - val_loss: 3.6237e-05\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3360e-05 - val_loss: 3.9447e-05\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.0410e-05 - val_loss: 5.1463e-05\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.5222e-05 - val_loss: 4.2167e-05\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.1042e-05 - val_loss: 4.0038e-05\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.9189e-05 - val_loss: 3.8485e-05\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7504e-05 - val_loss: 4.1784e-05\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.1634e-05 - val_loss: 4.1121e-05\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.0008e-05 - val_loss: 3.2353e-05\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7094e-05 - val_loss: 4.9977e-05\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5038e-05 - val_loss: 7.1497e-05\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1160e-05 - val_loss: 5.0746e-05\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3148e-05 - val_loss: 4.0004e-05\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.0113e-05 - val_loss: 3.6839e-05\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.6313e-05 - val_loss: 3.9067e-05\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.8049e-05 - val_loss: 3.5744e-05\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9701e-05 - val_loss: 4.3399e-05\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9155e-05 - val_loss: 3.3108e-05\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.3428e-05 - val_loss: 4.2919e-05\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 0s 6ms/step - loss: 2.7271e-05 - val_loss: 3.8001e-05\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9109e-05 - val_loss: 3.3506e-05\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9235e-05 - val_loss: 3.8231e-05\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.8178e-05 - val_loss: 3.1548e-05\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 1.9883e-05 - val_loss: 4.1819e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练模型\n",
    "\n",
    "history =model.fit(x=x_train, y=y_train, epochs=200,batch_size=32,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mememe.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = load_model(\"mememe.h5\", custom_objects={\"Adam\": Adam})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_csv1 = pd.read_csv(\"./1638.csv\")#读取filtered file\n",
    "# data_csv1 = pd.read_csv(\"./1551.csv\", sep='\\t') \n",
    "trajectory1 = np.array(data_csv1, dtype=np.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataX1 shape: (6, 10, 5)\n",
      "dataY1 shape: (6, 2)\n",
      "dataX1 shape: (6, 5, 10)\n",
      "[[[     2.          3.          4.          5.          6.\n",
      "        7.          8.          9.         10.         11.    ]\n",
      "  [679861.0741 679861.0762 679861.0765 679861.0665 679861.0424\n",
      "   679861.008  679860.9717 679860.9376 679860.9031 679860.8668]\n",
      "  [419361.0572 419361.0749 419360.9844 419360.7966 419360.5068\n",
      "   419360.1194 419359.6241 419359.1486 419358.6731 419358.1778]\n",
      "  [     0.74        2.27        4.73        7.86       10.98\n",
      "       13.44       15.01       15.6        15.27       14.31  ]\n",
      "  [     9.5        11.21       11.2        11.19       11.2\n",
      "       11.21       10.07        0.56       -6.53      -11.2   ]]\n",
      "\n",
      " [[     3.          4.          5.          6.          7.\n",
      "        8.          9.         10.         11.         12.    ]\n",
      "  [679861.0762 679861.0765 679861.0665 679861.0424 679861.008\n",
      "   679860.9717 679860.9376 679860.9031 679860.8668 679860.8342]\n",
      "  [419361.0749 419360.9844 419360.7966 419360.5068 419360.1194\n",
      "   419359.6241 419359.1486 419358.6731 419358.1778 419357.7712]\n",
      "  [     2.27        4.73        7.86       10.98       13.44\n",
      "       15.01       15.6        15.27       14.31       13.05  ]\n",
      "  [    11.21       11.2        11.19       11.2        11.21\n",
      "       10.07        0.56       -6.53      -11.2       -11.2   ]]\n",
      "\n",
      " [[     4.          5.          6.          7.          8.\n",
      "        9.         10.         11.         12.         13.    ]\n",
      "  [679861.0765 679861.0665 679861.0424 679861.008  679860.9717\n",
      "   679860.9376 679860.9031 679860.8668 679860.8342 679860.8102]\n",
      "  [419360.9844 419360.7966 419360.5068 419360.1194 419359.6241\n",
      "   419359.1486 419358.6731 419358.1778 419357.7712 419357.3935]\n",
      "  [     4.73        7.86       10.98       13.44       15.01\n",
      "       15.6        15.27       14.31       13.05       12.11  ]\n",
      "  [    11.2        11.19       11.2        11.21       10.07\n",
      "        0.56       -6.53      -11.2       -11.2        -6.25  ]]\n",
      "\n",
      " [[     5.          6.          7.          8.          9.\n",
      "       10.         11.         12.         13.         14.    ]\n",
      "  [679861.0665 679861.0424 679861.008  679860.9717 679860.9376\n",
      "   679860.9031 679860.8668 679860.8342 679860.8102 679860.7909]\n",
      "  [419360.7966 419360.5068 419360.1194 419359.6241 419359.1486\n",
      "   419358.6731 419358.1778 419357.7712 419357.3935 419357.0997]\n",
      "  [     7.86       10.98       13.44       15.01       15.6\n",
      "       15.27       14.31       13.05       12.11       12.11  ]\n",
      "  [    11.19       11.2        11.21       10.07        0.56\n",
      "       -6.53      -11.2       -11.2        -6.25        6.26  ]]\n",
      "\n",
      " [[     6.          7.          8.          9.         10.\n",
      "       11.         12.         13.         14.         15.    ]\n",
      "  [679861.0424 679861.008  679860.9717 679860.9376 679860.9031\n",
      "   679860.8668 679860.8342 679860.8102 679860.7909 679860.7699]\n",
      "  [419360.5068 419360.1194 419359.6241 419359.1486 419358.6731\n",
      "   419358.1778 419357.7712 419357.3935 419357.0997 419356.7221]\n",
      "  [    10.98       13.44       15.01       15.6        15.27\n",
      "       14.31       13.05       12.11       12.11       13.04  ]\n",
      "  [    11.2        11.21       10.07        0.56       -6.53\n",
      "      -11.2       -11.2        -6.25        6.26       11.2   ]]\n",
      "\n",
      " [[     7.          8.          9.         10.         11.\n",
      "       12.         13.         14.         15.         16.    ]\n",
      "  [679861.008  679860.9717 679860.9376 679860.9031 679860.8668\n",
      "   679860.8342 679860.8102 679860.7909 679860.7699 679860.7419]\n",
      "  [419360.1194 419359.6241 419359.1486 419358.6731 419358.1778\n",
      "   419357.7712 419357.3935 419357.0997 419356.7221 419356.3152]\n",
      "  [    13.44       15.01       15.6        15.27       14.31\n",
      "       13.05       12.11       12.11       13.04       14.31  ]\n",
      "  [    11.21       10.07        0.56       -6.53      -11.2\n",
      "      -11.2        -6.25        6.26       11.2        11.2   ]]]\n",
      "[[679860.8342 419357.7712]\n",
      " [679860.8102 419357.3935]\n",
      " [679860.7909 419357.0997]\n",
      " [679860.7699 419356.7221]\n",
      " [679860.7419 419356.3152]\n",
      " [679860.7099 419355.8196]]\n"
     ]
    }
   ],
   "source": [
    "dataX1, dataY1 = [], []\n",
    "window_size = 10\n",
    "step_size = 1\n",
    "\n",
    "for i in range(0, len(trajectory1) - window_size, step_size):\n",
    "    dataX1.append(trajectory1[i:i+window_size,0:5])\n",
    "    dataY1.append(trajectory1[i+window_size,1:3])\n",
    "\n",
    " # 将输入数据和目标数据转换为numpy数组\n",
    "dataX1 = np.array(dataX1, dtype='float64')\n",
    "dataY1 = np.array(dataY1, dtype='float64')\n",
    "# dataY = dataY.reshape(2408,1,2)\n",
    "print('dataX1 shape:', dataX1.shape) # (91, 10, 3)\n",
    "print('dataY1 shape:', dataY1.shape) # (91, 2)\n",
    "# 使用transpose()方法交换第二维度和第三维度\n",
    "dataX1 = dataX1.transpose((0, 2, 1))\n",
    "print('dataX1 shape:', dataX1.shape)\n",
    "\n",
    "print(dataX1)\n",
    "print(dataY1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new X_data shape : (6, 5, 10)\n",
      "y_data shape : (6, 2)\n",
      "new y_data shape : (6, 2)\n",
      "[[ 1.                 1.               ]\n",
      " [ 0.613837487995625  0.612932978023309]\n",
      " [ 0.303298471495509  0.311846689903177]\n",
      " [-0.034593725576997 -0.075117852014955]\n",
      " [-0.48511665314436  -0.492109038750641]\n",
      " [-1.                -1.               ]]\n"
     ]
    }
   ],
   "source": [
    "# Preporcessing Normalizing Valuse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "# new_df= x_data.reshape(x_data.shape[0],5)\n",
    "dataX1=dataX1.reshape(6,50)\n",
    "new_x_data = sc.fit_transform(dataX1)\n",
    "new_x_data = new_x_data.reshape(6,5,10)\n",
    "\n",
    "# print('X_data shape :', x_data.shape)\n",
    "print('new X_data shape :', new_x_data.shape)\n",
    "\n",
    "# y_data=y_data.reshape(2408,2)\n",
    "new_y_data = sc.fit_transform(dataY1)\n",
    "# new_y_data = new_y_data.reshape(2408,2)\n",
    "print('y_data shape :', dataY1.shape)\n",
    "print('new y_data shape :', new_y_data.shape)\n",
    "# print(new_x_data)\n",
    "print(new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(new_x_data[0:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.28257528  0.11931215]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "[[679860.75 419356.9 ]]\n"
     ]
    }
   ],
   "source": [
    "# # 设置打印选项，精度为3位小数\n",
    "# np.set_printoptions(precision=5, suppress=True)\n",
    "np.set_printoptions(precision=15, suppress=True)\n",
    "res_df = sc.inverse_transform(result)\n",
    "# res_df.reshape(new_df.shape[0],5,1)\n",
    "# res_df\n",
    "print(res_df.shape)\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679860.8342 419357.7712]]\n",
      "[[     2.          3.          4.          5.          6.          7.\n",
      "       8.          9.         10.         11.     679861.0741 679861.0762\n",
      "  679861.0765 679861.0665 679861.0424 679861.008  679860.9717 679860.9376\n",
      "  679860.9031 679860.8668 419361.0572 419361.0749 419360.9844 419360.7966\n",
      "  419360.5068 419360.1194 419359.6241 419359.1486 419358.6731 419358.1778\n",
      "       0.74        2.27        4.73        7.86       10.98       13.44\n",
      "      15.01       15.6        15.27       14.31        9.5        11.21\n",
      "      11.2        11.19       11.2        11.21       10.07        0.56\n",
      "      -6.53      -11.2   ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataY1[0:1])\n",
    "print(dataX1[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413 419832.253 ]\n",
      " [679955.8419 419832.2448]\n",
      " [679878.8793 419458.8907]\n",
      " ...\n",
      " [679955.8474 419832.1637]\n",
      " [679955.844  419832.2116]\n",
      " [679955.8437 419832.2183]]\n",
      "(723, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.reshape (723, 2)  #需要改的地方\n",
    "# y_test_actual=sc.inverse_transform(y_test[2:3])\n",
    "y_test_actual=sc.inverse_transform(y_test)\n",
    "print(y_test_actual)\n",
    "print(y_test_actual.shape)\n",
    "# for i in range(len(result)):\n",
    "#     plt.scatter(result[0][i],result[1][i],c='r')\n",
    "#     plt.scatter(y_test[0][i],y_test[1][i],c='g')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制预测值和实际值\n",
    "\n",
    "predicted_df = pd.DataFrame(data=res_df[0:,0:],index=[i for i in range(res_df.shape[0])],columns=['f'+str(i) for i in range(res_df.shape[1])])\n",
    "\n",
    "actual_df = pd.DataFrame(data=y_test_actual[0:,0:],index=[i for i in range(y_test_actual.shape[0])],columns=['f'+str(i) for i in range(y_test_actual.shape[1])])\n",
    "\n",
    "# for i in range(len(res_df)):\n",
    "# #   print(i)\n",
    "plt.scatter(x=predicted_df['f0'],y=predicted_df['f1'],c='r',s=0.1,alpha=0.5)\n",
    "plt.scatter(x=actual_df['f0'],y=actual_df['f1'],c='b',s=0.1,alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.1907147750826446\n",
      "MAE: 0.5062718879662385\n",
      "相关系数为： 0.9597269629903625\n",
      "R^2: 0.9999129070402\n",
      "Correlation coefficient: 0.9597269629903625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# # 定义真实定位数据和预测数据\n",
    "# true_pos = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "# pred_pos = np.array([[0.5, 1.5], [3.2, 3.9], [4.9, 6.2]])\n",
    "\n",
    "# 计算均方误差\n",
    "mse = mean_squared_error(actual_df, predicted_df)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "# 计算平均绝对误差\n",
    "mae = mean_absolute_error(actual_df, predicted_df)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# 计算相关系数矩阵\n",
    "corr_matrix = np.corrcoef(actual_df.T, predicted_df.T)\n",
    "corr_coefficient = corr_matrix[0, 1] # 取出相关系数值\n",
    "print(\"相关系数为：\", corr_coefficient) # 打印相关系数\n",
    "# 计算决定系数\n",
    "r2 = r2_score(actual_df, predicted_df)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 将实际值和预测值分别存储在矩阵中\n",
    "actual_matrix = np.array(actual_df)\n",
    "predicted_matrix = np.array(predicted_df)\n",
    "correlation_matrix = np.corrcoef(actual_matrix, predicted_matrix, rowvar=False) # 计算相关系数（Pearson相关系数）\n",
    "correlation_coefficient = correlation_matrix[0, 1] # 提取相关系数矩阵中的相关系数\n",
    "print(\"Correlation coefficient:\", correlation_coefficient) # 打印相关系数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413  419832.253   679955.8125  419832.875  ]\n",
      " [679955.8419  419832.2448  679955.875   419832.90625]\n",
      " [679878.8793  419458.8907  679878.9375  419458.53125]\n",
      " ...\n",
      " [679955.8474  419832.1637  679955.875   419832.8125 ]\n",
      " [679955.844   419832.2116  679955.875   419832.96875]\n",
      " [679955.8437  419832.2183  679955.875   419832.96875]]\n"
     ]
    }
   ],
   "source": [
    " #合并两个矩阵\n",
    "merged_matrix = np.concatenate((y_test_actual, res_df), axis=1)#真实,预测\n",
    "\n",
    "print(merged_matrix) # 输出合并后矩阵的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6226664   0.66227767  0.36413122  0.26459088  0.08469244  1.85713936\n",
      "  0.87765128  0.16354758  0.33328525  0.20824957  1.99902845  0.27888195\n",
      "  0.36360951  0.65058571  2.64942995  0.41439291  1.04870255  0.20929262\n",
      "  0.14209311  0.01920521  0.09367162  2.28929232  3.8924384   0.43888526\n",
      "  0.47791025  0.34997243  0.85168968  4.02981488  0.09367162  0.1110363\n",
      "  0.31530521  0.1531014   1.38249054  0.15905285  0.36311788  0.38209536\n",
      "  0.13355475  1.53137161  3.47403167  0.08469244  0.16285828  4.64166096\n",
      "  0.19412792  4.36944307  0.79088052  4.58028203  2.31177534  0.90359032\n",
      "  0.13355475  0.11986923  0.61302195  0.13355475  1.29589373  1.08884044\n",
      "  0.3717153   0.53696423  1.53687633  5.64210816  0.20229904 10.05793475\n",
      "  1.62070289  0.13915391  7.66466023  0.09837582  0.53626509  0.14924105\n",
      "  0.69956935  0.73513444  0.11244999  0.12417572  0.08469244  0.13127837\n",
      "  0.09367162  0.36132237  0.09367162  0.23584016  0.03531926  0.13871223\n",
      "  0.48608062  0.41009035  0.64884292  0.71081616  0.21091859  0.74717864\n",
      "  0.1110363   0.10194735  0.37880486  3.0342548   2.11644408  0.39687797\n",
      "  0.12629173  3.06372434  2.14238288  0.53301326  0.69878143  1.08832978\n",
      "  0.54667287  0.68636729  0.08469244  1.54856517  0.27406001  0.46850184\n",
      "  0.34159035  0.75419977  0.85811246  0.31474134  1.1294308   2.82447736\n",
      "  0.07479113  0.17291969  0.33996941  0.66858646  0.1539203   0.10314635\n",
      "  0.14638173  0.3440106   0.57862303  0.16354758  0.73532284  0.45486808\n",
      "  3.43986846  0.77736533  5.47108881  0.21082439  1.42870461  0.45605285\n",
      "  0.43210625  0.1825793   0.40946709  0.13355475  0.46525627  3.10644647\n",
      " 17.51332558  0.09479251  0.34932589  0.19347687  0.19929014  0.20464658\n",
      "  0.58163403  0.27358035  0.21067893  1.19327357  0.21084622  0.53637066\n",
      "  0.10339889  0.11126011  0.64600317  6.63502898  0.80551472  0.23477044\n",
      "  3.18363375  0.09367162  0.09367162  1.35968638  0.33328525  0.73902461\n",
      "  0.42620089  0.15806796  6.96197539  0.33931076  0.29179378  0.28459622\n",
      "  0.10172823  0.47668239  3.54692233  0.4328235   1.71706289  0.19744005\n",
      "  6.81512393  0.67264139  0.14694067  0.11151194  0.35290707  0.13355475\n",
      "  0.20045456  0.05561801  0.14694067  0.27326326  0.30141865  0.7074332\n",
      "  0.44876532  0.46061938  1.03949049  0.14694067  0.17299697  0.18346581\n",
      "  0.41551099  0.97234353  2.58611519  0.19526661  0.34953027  2.40352628\n",
      "  1.20789266  0.21466034  0.3119854   0.76296388  0.20390118  0.39714242\n",
      "  0.15229288  0.1626198   0.30124762  0.4140231   0.70195277  0.27326326\n",
      "  0.58017421  0.69140171 18.6777458   0.17187295  0.14710738  0.27458334\n",
      "  0.92033493  0.1110363   0.23431347  0.11206615  0.4592601   0.13355475\n",
      "  2.09830719  0.16354758  0.75152149  4.76775936  1.46132368  0.67394025\n",
      "  0.75050297  0.53876201  0.15229288  6.87450971  0.2172117   0.27014479\n",
      "  6.66223221  0.28517148  0.26876893  0.1397559   3.34748816  0.1110363\n",
      "  0.33328525  0.36980075  0.96827165  1.7288586   0.32274648  0.36856807\n",
      "  0.79654373  0.16467811  0.61955586  0.15229288  0.67812419  0.72203664\n",
      "  0.08066308  0.15873346  0.12714409  0.10274288  0.16140895  5.4761039\n",
      "  0.22175338 12.40015365  0.37576722  0.10824463  3.58353539  0.14973067\n",
      "  0.07410049 12.12484254  0.13355475  3.16763065  0.16023046  0.46331383\n",
      "  0.16354758  0.7044501   0.38832438  0.32587806  1.25030088  0.38887422\n",
      "  4.04136875  0.43469624  0.41324737  3.95422752  0.08823731  0.48608062\n",
      "  0.72452263  3.703337    0.32542452  0.09077031  0.33596438  0.45639764\n",
      "  0.16354758  0.44635083  0.61775777  0.33328525  0.56569471  0.15229288\n",
      "  0.32320826  0.56675107  0.76116533  0.19167861  0.30452616  0.41226074\n",
      "  0.1877276   0.2833639   1.51866904  0.54671236  0.15229288  0.42556589\n",
      "  0.24150624  0.19929014  0.30314909  0.07449248  0.70944168  0.78151855\n",
      "  0.08913596  1.93892846  0.08469244  0.17898422  0.53936127  0.72392311\n",
      "  0.42631037  0.14530059  0.15229288  0.21466034  0.67572623  0.34274428\n",
      "  0.61835713  4.08776705  0.20903017  1.51408431  0.43745994  0.37610758\n",
      "  0.17188127  0.73840967  0.65223481  1.47988665  1.14007605 16.09496285\n",
      "  0.76535002  0.25157466  0.21133424  0.69897001  0.08469244  0.57345893\n",
      "  3.89778402  0.16704014  0.14694067  0.20224156  0.68970157  0.45431056\n",
      "  0.04795081  0.88382635  0.25684632  0.47504759  0.64707503  0.62470964\n",
      "  0.12200098  0.15846829  0.4448654   0.21245068  4.37050511  0.35967358\n",
      "  0.4718628   0.13724577  0.54340137  3.68961928  0.13355475  0.28097623\n",
      "  0.79261821  0.20124749  0.15650489  0.08469244  0.48998619  1.6088866\n",
      "  2.51516052  0.0970675   0.30749257  0.35824419  0.75718516  0.67998697\n",
      "  0.17815782  0.35277955  0.81607437  0.22585661  0.27262054  0.75526797\n",
      "  0.29311476  0.27810051  0.01658229  0.74597957  0.47346214  0.15033217\n",
      "  0.10285613  1.09087914  0.46297785  0.13355475  0.24371986  0.20568714\n",
      "  0.19153864  0.42628275  0.09367162  0.19692443  2.79663558  0.30314909\n",
      "  0.70135341  3.63438505  0.15229288  0.18382048  0.95535465  3.21442876\n",
      "  0.37132951  0.7580841   0.07725076  0.19314638  0.54774481  0.03622292\n",
      "  2.88612748  0.13060747  0.14262275  0.39882084  0.28845917  0.1795985\n",
      "  0.16052602  0.21604752  0.27515176  0.88712608  0.35846268  0.3699011\n",
      "  0.48608062  0.17979016  0.06906178  0.04663821  0.59422744  0.28642132\n",
      "  0.51112643  0.36360951  0.1860974   0.25590203  0.18297643  2.7368676\n",
      "  1.65957833  0.02837834  0.15905285  0.26724087  0.44641379  0.37105151\n",
      "  0.0873284   0.12674949  0.13544656  0.53195528  0.42228677  0.08469244\n",
      "  0.13171124  0.53410997  0.18411738  1.27870591  0.63892312  0.18443668\n",
      "  0.24371986  0.18626124  0.19176616  0.71201496  0.32680908  0.75290089\n",
      "  0.08469244  0.12335478  0.15905285  0.15420616  1.57264834  0.24371986\n",
      "  0.64750137  0.08469244  0.10107918  0.54220292  2.08633162  0.21445839\n",
      "  0.8267884   0.29826779  5.80874373  0.56345001  3.38397002  0.26096636\n",
      "  0.45533401  0.1110363   0.16446024  0.24439069  0.45813483  0.73530839\n",
      "  0.08401631  0.13355475  2.27959553  0.33650214  0.72263616  0.1736039\n",
      "  1.00569849  0.17579984  0.33977419  0.10888269  0.11879701  0.51688762\n",
      "  0.10618258  0.20740652  0.41226556  0.15229288  1.54886658  0.54280215\n",
      "  0.41606238  0.53303114  0.1795985   0.33058514  0.22435123  0.563961\n",
      "  1.50612044  0.07814047  0.47222733  0.70206659  0.13355475  0.48512322\n",
      "  0.23359735  1.75726602  0.27534941  0.40318082  0.35235149  0.22689777\n",
      "  3.52325732  0.1795985   0.84546423  0.12689602  0.11176642  0.6570994\n",
      "  4.64481007  0.502149    0.31947828  2.11491133  2.10998194  2.93887335\n",
      "  0.82496296  0.19656605  0.44343468  1.209226    0.09367162  1.94542117\n",
      "  0.14694067  0.1110363   0.05683881  0.61895649  0.72711988  4.71359175\n",
      "  0.18803247  0.28016085  0.1505384   0.30472073  1.67310261  0.57015464\n",
      "  0.08469244  0.14694067  0.75598586  0.12810671  0.15905285  0.22657559\n",
      "  0.18131553  1.95103515  0.47847772  0.09367162  0.15229288  0.15905285\n",
      "  2.15433261  0.42173956  1.29284496  0.1795985   0.35168034  0.61715841\n",
      "  1.05923392  0.16354758  0.24896444  0.29780504  0.15735952  1.3658514\n",
      "  0.67237669  0.21835148  0.08469244  0.168993    0.10853369  0.66575701\n",
      "  0.18649027  0.22330069  0.36638881  0.56361559 13.84633096  0.14694067\n",
      "  0.26040572  0.08469244  0.49684282  0.47499176  0.80471618  1.36586194\n",
      "  0.98782736  0.88384788  0.15905285  0.48848109  0.09277694  0.70361648\n",
      "  0.16204574  0.65264474  0.45148816  0.42837462  2.08962296  0.4576142\n",
      "  0.03114161  0.39314655  0.47304359  0.38454987  0.2338386   0.1110363\n",
      "  0.20344302  0.7465791   1.78554779  0.27221638  0.34116231  0.70057994\n",
      "  0.14694067  0.64359688  0.18203914  0.19350753  0.13823531  0.1396761\n",
      "  0.3119381   0.08116472  0.41453308  1.94952044  0.1110363   0.75718485\n",
      "  0.12154202  0.42849258  0.4232689   0.37552461  0.14694067  0.14961524\n",
      "  0.27310117  0.48608062  1.89533951  1.6183813   0.38870628  0.22651501\n",
      "  2.77156381  0.67958612  0.2358366   2.82527764  0.24212883  0.60453797\n",
      "  0.15229288  0.58343192  0.10207851  0.64881239  0.65979592  0.68678559\n",
      "  0.42227101  0.48608062  0.65769863  0.41161961  0.21466034  0.30771051\n",
      "  0.37515339  0.1110363   0.30730899  0.27326326  0.13355475  0.30673434\n",
      "  0.44186283  0.08469244  0.38303345  0.58043544  0.13355475  0.16905751\n",
      "  0.39407843  0.46174203  0.72770634  0.04671242  0.59060974  0.13888675\n",
      "  0.50945008  0.16612525  0.7413861   0.08469244  1.70493837  0.53631117\n",
      "  0.17956041  0.33877657  0.74967671  0.80985856  0.39333675  0.38712731\n",
      "  0.24116543  0.16209692  3.37889747  0.2981492   0.44951111  0.07666128\n",
      "  0.09367162  0.1795985   0.1110363   0.19686264  0.46190065 20.68790282\n",
      "  0.59053137  0.70683382  1.75394095  0.77221169  2.45632584  0.52221154\n",
      "  0.36360951  0.03419898  0.63190284  0.42457307  3.09048142  0.25363188\n",
      "  0.15905285  0.80843302  0.08469244  0.27447902  0.17935343  0.13355475\n",
      "  0.15229288  0.74509217  2.4738449   3.04681664  0.2597011   0.14405711\n",
      "  0.64938679  0.75778435  0.75110245]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 计算每行数据中两个点之间的欧式距离\n",
    "distances = np.linalg.norm(merged_matrix[:, :2] - merged_matrix[:, 2:], axis=1)\n",
    "print(distances)\n",
    "np.savetxt('distances.txt', distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.用库\n",
    "2.分析误差\n",
    "3.v2x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
