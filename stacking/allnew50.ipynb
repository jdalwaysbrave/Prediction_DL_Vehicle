{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape : (2408, 50)\n",
      "new X_data shape : (2408, 5, 10)\n",
      "y_data shape : (2408, 2)\n",
      "new y_data shape : (2408, 2)\n",
      "[[-1.         -1.        ]\n",
      " [-0.99969315 -0.99884536]\n",
      " [-0.99938229 -0.99769038]\n",
      " ...\n",
      " [ 0.66212312  0.99439013]\n",
      " [ 0.65831461  0.99719455]\n",
      " [ 0.65450609  1.        ]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 32)                4224      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,290\n",
      "Trainable params: 4,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 2s 11ms/step - loss: 0.1959 - val_loss: 0.0429\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0306 - val_loss: 0.0198\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0117 - val_loss: 0.0105\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0051\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 9.8316e-04 - val_loss: 9.2150e-04\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 8.9389e-04 - val_loss: 8.8412e-04\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.9922e-04 - val_loss: 8.0162e-04\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 7.3075e-04 - val_loss: 7.3415e-04\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.7849e-04 - val_loss: 8.0663e-04\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 6.5063e-04 - val_loss: 6.1673e-04\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.9733e-04 - val_loss: 5.8429e-04\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.4343e-04 - val_loss: 5.7901e-04\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 5.1342e-04 - val_loss: 5.1823e-04\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.8033e-04 - val_loss: 5.1349e-04\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.7186e-04 - val_loss: 4.9998e-04\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.4034e-04 - val_loss: 4.8627e-04\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.3171e-04 - val_loss: 4.6381e-04\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 4.1892e-04 - val_loss: 4.2369e-04\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7657e-04 - val_loss: 4.0049e-04\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.7173e-04 - val_loss: 4.1182e-04\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.5123e-04 - val_loss: 3.7688e-04\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.3610e-04 - val_loss: 3.8045e-04\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.2344e-04 - val_loss: 4.0875e-04\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.1358e-04 - val_loss: 3.4125e-04\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 3.0071e-04 - val_loss: 3.4663e-04\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.9150e-04 - val_loss: 3.3496e-04\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.9001e-04 - val_loss: 3.3045e-04\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 0s 4ms/step - loss: 2.7876e-04 - val_loss: 3.5685e-04\n",
      "53/53 [==============================] - 0s 1ms/step\n",
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM,RNN\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Embedding, LSTM, Dropout, Activation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "np.set_printoptions(suppress=True)  # 关闭科学计数法\n",
    "\n",
    "data_csv = pd.read_csv(\"./filtered.csv\")#读取filtered file\n",
    "trajectory = np.array(data_csv, dtype=np.float64)  # trajectory1[:, 2:9] 原为2个数据 现为8个\n",
    "dataX, dataY = [], []\n",
    "    # 定义滑动窗口的大小和步长\n",
    "window_size = 10\n",
    "step_size = 1\n",
    "\n",
    " # 创建输入数据和目标数据\n",
    "\n",
    "    # 创建输入数据和目标数据\n",
    "\n",
    "for i in range(0, len(trajectory) - window_size, step_size):\n",
    "    dataX.append(trajectory[i:i+window_size])\n",
    "    dataY.append(trajectory[i+window_size,1:3])\n",
    "\n",
    " # 将输入数据和目标数据转换为numpy数组\n",
    "dataX = np.array(dataX, dtype='float64')\n",
    "dataY = np.array(dataY, dtype='float64')\n",
    "# dataY = dataY.reshape(2408,1,2)\n",
    "# print('dataX shape:', dataX.shape) # (91, 10, 3)\n",
    "# print('dataY shape:', dataY.shape) # (91, 2)\n",
    "# 使用transpose()方法交换第二维度和第三维度\n",
    "dataX = dataX.transpose((0, 2, 1))\n",
    "# print('dataX shape:', dataX.shape)\n",
    "train_x = dataX\n",
    "train_y= dataY\n",
    "x_data = train_x\n",
    "x_data = np.array(x_data)\n",
    "# x_data = x_data.reshape(19828,5,1)\n",
    "y_data = train_y\n",
    "y_data.shape\n",
    "# Preporcessing Normalizing Valuse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "# new_df= x_data.reshape(x_data.shape[0],5)\n",
    "x_data=x_data.reshape(2408,50)\n",
    "new_x_data = sc.fit_transform(x_data)\n",
    "new_x_data = new_x_data.reshape(2408,5,10)\n",
    "print('X_data shape :', x_data.shape)\n",
    "print('new X_data shape :', new_x_data.shape)\n",
    "# y_data=y_data.reshape(2408,2)\n",
    "new_y_data = sc.fit_transform(y_data)\n",
    "# new_y_data = new_y_data.reshape(2408,2)\n",
    "print('y_data shape :', y_data.shape)\n",
    "print('new y_data shape :', new_y_data.shape)\n",
    "# print(new_x_data)\n",
    "print(new_y_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_x_data, new_y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "# 创建GRU模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(units=32, input_shape=(5,10)),\n",
    "    tf.keras.layers.Dense(units=2),\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "# 训练模型\n",
    "\n",
    "history =model.fit(x=x_train, y=y_train, epochs=50,batch_size=32,validation_data=(x_test,y_test))\n",
    "model.save(\"gru.h5\")\n",
    "model = load_model(\"gru.h5\")\n",
    "gru_pred_train = model.predict(x_train)\n",
    "gru_pred_test = model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataX shape: (2408, 10, 5)\n",
      "dataY shape: (2408, 2)\n",
      "dataX shape: (2408, 5, 10)\n",
      "[[[     0.          1.          2.     ...      7.          8.\n",
      "        9.    ]\n",
      "  [679864.4007 679864.4159 679864.4315 ... 679864.5083 679864.5238\n",
      "   679864.5391]\n",
      "  [419283.8057 419284.144  419284.4826 ... 419286.1755 419286.5141\n",
      "   419286.8528]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     1.          2.          3.     ...      8.          9.\n",
      "       10.    ]\n",
      "  [679864.4159 679864.4315 679864.4467 ... 679864.5238 679864.5391\n",
      "   679864.5546]\n",
      "  [419284.144  419284.4826 419284.8213 ... 419286.5141 419286.8528\n",
      "   419287.1914]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     2.          3.          4.     ...      9.         10.\n",
      "       11.    ]\n",
      "  [679864.4315 679864.4467 679864.4623 ... 679864.5391 679864.5546\n",
      "   679864.5699]\n",
      "  [419284.4826 419284.8213 419285.1599 ... 419286.8528 419287.1914\n",
      "   419287.53  ]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  2405.       2406.       2407.     ...   2412.       2413.\n",
      "     2414.    ]\n",
      "  [679949.3305 679949.1406 679948.9507 ... 679948.0009 679947.811\n",
      "   679947.6212]\n",
      "  [419863.8233 419864.646  419865.4683 ... 419869.581  419870.4036\n",
      "   419871.226 ]\n",
      "  [    27.74       27.7        27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.38       -0.19        0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2406.       2407.       2408.     ...   2413.       2414.\n",
      "     2415.    ]\n",
      "  [679949.1406 679948.9507 679948.7608 ... 679947.811  679947.6212\n",
      "   679947.4313]\n",
      "  [419864.646  419865.4683 419866.291  ... 419870.4036 419871.226\n",
      "   419872.0486]\n",
      "  [    27.7        27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.19        0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2407.       2408.       2409.     ...   2414.       2415.\n",
      "     2416.    ]\n",
      "  [679948.9507 679948.7608 679948.5709 ... 679947.6212 679947.4313\n",
      "   679947.2414]\n",
      "  [419865.4683 419866.291  419867.1133 ... 419871.226  419872.0486\n",
      "   419872.871 ]\n",
      "  [    27.69       27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]]\n",
      "[[679864.5546 419287.1914]\n",
      " [679864.5699 419287.53  ]\n",
      " [679864.5854 419287.8687]\n",
      " ...\n",
      " [679947.4313 419872.0486]\n",
      " [679947.2414 419872.871 ]\n",
      " [679947.0515 419873.6937]]\n",
      "X_data shape : (2408, 50)\n",
      "new X_data shape : (2408, 5, 10)\n",
      "y_data shape : (2408, 2)\n",
      "new y_data shape : (2408, 2)\n",
      "[[-1.         -1.        ]\n",
      " [-0.99969315 -0.99884536]\n",
      " [-0.99938229 -0.99769038]\n",
      " ...\n",
      " [ 0.66212312  0.99439013]\n",
      " [ 0.65831461  0.99719455]\n",
      " [ 0.65450609  1.        ]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 50)             12200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 5, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 100)            60400     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 102,902\n",
      "Trainable params: 102,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "53/53 [==============================] - 7s 22ms/step - loss: 0.2688 - accuracy: 0.6950 - val_loss: 0.1029 - val_accuracy: 0.9281\n",
      "Epoch 2/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1280 - accuracy: 0.7507 - val_loss: 0.0816 - val_accuracy: 0.6916\n",
      "Epoch 3/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1262 - accuracy: 0.7484 - val_loss: 0.0822 - val_accuracy: 0.7649\n",
      "Epoch 4/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1187 - accuracy: 0.7478 - val_loss: 0.0804 - val_accuracy: 0.8686\n",
      "Epoch 5/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1108 - accuracy: 0.7840 - val_loss: 0.0732 - val_accuracy: 0.9557\n",
      "Epoch 6/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.7875 - val_loss: 0.0832 - val_accuracy: 0.9668\n",
      "Epoch 7/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1085 - accuracy: 0.8000 - val_loss: 0.0697 - val_accuracy: 0.8562\n",
      "Epoch 8/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.1036 - accuracy: 0.8196 - val_loss: 0.0760 - val_accuracy: 0.9654\n",
      "Epoch 9/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.1003 - accuracy: 0.8148 - val_loss: 0.0622 - val_accuracy: 0.9419\n",
      "Epoch 10/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0921 - accuracy: 0.8154 - val_loss: 0.0567 - val_accuracy: 0.8451\n",
      "Epoch 11/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0875 - accuracy: 0.8125 - val_loss: 0.0648 - val_accuracy: 0.8008\n",
      "Epoch 12/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.8125 - val_loss: 0.0611 - val_accuracy: 0.9903\n",
      "Epoch 13/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0832 - accuracy: 0.8291 - val_loss: 0.0408 - val_accuracy: 0.7400\n",
      "Epoch 14/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0758 - accuracy: 0.8231 - val_loss: 0.0368 - val_accuracy: 0.8672\n",
      "Epoch 15/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0738 - accuracy: 0.8409 - val_loss: 0.0370 - val_accuracy: 0.8811\n",
      "Epoch 16/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0710 - accuracy: 0.8172 - val_loss: 0.0338 - val_accuracy: 0.8354\n",
      "Epoch 17/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.8309 - val_loss: 0.0335 - val_accuracy: 0.9502\n",
      "Epoch 18/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0695 - accuracy: 0.8196 - val_loss: 0.0342 - val_accuracy: 0.8880\n",
      "Epoch 19/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0677 - accuracy: 0.8291 - val_loss: 0.0473 - val_accuracy: 0.8893\n",
      "Epoch 20/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0678 - accuracy: 0.8237 - val_loss: 0.0234 - val_accuracy: 0.8811\n",
      "Epoch 21/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0632 - accuracy: 0.8475 - val_loss: 0.0373 - val_accuracy: 0.9599\n",
      "Epoch 22/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0635 - accuracy: 0.8326 - val_loss: 0.0241 - val_accuracy: 0.8880\n",
      "Epoch 23/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0624 - accuracy: 0.8309 - val_loss: 0.0250 - val_accuracy: 0.8340\n",
      "Epoch 24/50\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0599 - accuracy: 0.8380 - val_loss: 0.0269 - val_accuracy: 0.8465\n",
      "Epoch 25/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0616 - accuracy: 0.8356 - val_loss: 0.0237 - val_accuracy: 0.9073\n",
      "Epoch 26/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0606 - accuracy: 0.8481 - val_loss: 0.0238 - val_accuracy: 0.8769\n",
      "Epoch 27/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0571 - accuracy: 0.8576 - val_loss: 0.0209 - val_accuracy: 0.9848\n",
      "Epoch 28/50\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0579 - accuracy: 0.8504 - val_loss: 0.0209 - val_accuracy: 0.8313\n",
      "Epoch 29/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0582 - accuracy: 0.8588 - val_loss: 0.0228 - val_accuracy: 0.8548\n",
      "Epoch 30/50\n",
      "53/53 [==============================] - 1s 16ms/step - loss: 0.0578 - accuracy: 0.8576 - val_loss: 0.0188 - val_accuracy: 0.9281\n",
      "Epoch 31/50\n",
      "53/53 [==============================] - 1s 15ms/step - loss: 0.0563 - accuracy: 0.8605 - val_loss: 0.0382 - val_accuracy: 0.9488\n",
      "Epoch 32/50\n",
      "53/53 [==============================] - 1s 13ms/step - loss: 0.0544 - accuracy: 0.8599 - val_loss: 0.0161 - val_accuracy: 0.9876\n",
      "Epoch 33/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0538 - accuracy: 0.8688 - val_loss: 0.0139 - val_accuracy: 0.9972\n",
      "Epoch 34/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0556 - accuracy: 0.8582 - val_loss: 0.0255 - val_accuracy: 0.9986\n",
      "Epoch 35/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0555 - accuracy: 0.8825 - val_loss: 0.0159 - val_accuracy: 0.9986\n",
      "Epoch 36/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0548 - accuracy: 0.8682 - val_loss: 0.0166 - val_accuracy: 0.9433\n",
      "Epoch 37/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 0.8611 - val_loss: 0.0150 - val_accuracy: 0.8963\n",
      "Epoch 38/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0545 - accuracy: 0.8819 - val_loss: 0.0139 - val_accuracy: 0.9834\n",
      "Epoch 39/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 0.8724 - val_loss: 0.0173 - val_accuracy: 0.9986\n",
      "Epoch 40/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0547 - accuracy: 0.8754 - val_loss: 0.0270 - val_accuracy: 0.9613\n",
      "Epoch 41/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0527 - accuracy: 0.8967 - val_loss: 0.0187 - val_accuracy: 0.9986\n",
      "Epoch 42/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0545 - accuracy: 0.8588 - val_loss: 0.0186 - val_accuracy: 0.9986\n",
      "Epoch 43/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0551 - accuracy: 0.8849 - val_loss: 0.0214 - val_accuracy: 0.9986\n",
      "Epoch 44/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0521 - accuracy: 0.8985 - val_loss: 0.0120 - val_accuracy: 0.9959\n",
      "Epoch 45/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0520 - accuracy: 0.8849 - val_loss: 0.0226 - val_accuracy: 0.9959\n",
      "Epoch 46/50\n",
      "53/53 [==============================] - 1s 12ms/step - loss: 0.0520 - accuracy: 0.8712 - val_loss: 0.0238 - val_accuracy: 0.9571\n",
      "Epoch 47/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0527 - accuracy: 0.9015 - val_loss: 0.0143 - val_accuracy: 0.9931\n",
      "Epoch 48/50\n",
      "53/53 [==============================] - 1s 11ms/step - loss: 0.0509 - accuracy: 0.8932 - val_loss: 0.0187 - val_accuracy: 0.9959\n",
      "Epoch 49/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0519 - accuracy: 0.9009 - val_loss: 0.0165 - val_accuracy: 0.9986\n",
      "Epoch 50/50\n",
      "53/53 [==============================] - 1s 10ms/step - loss: 0.0521 - accuracy: 0.8884 - val_loss: 0.0166 - val_accuracy: 0.9959\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM,RNN\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.set_printoptions(suppress=True)  # 关闭科学计数法\n",
    "\n",
    "data_csv = pd.read_csv(\"./filtered.csv\")#读取filtered file\n",
    "trajectory = np.array(data_csv, dtype=np.float64)  # trajectory1[:, 2:9] 原为2个数据 现为8个\n",
    "dataX, dataY = [], []\n",
    "    # 定义滑动窗口的大小和步长\n",
    "window_size = 10\n",
    "step_size = 1\n",
    "# 创建输入数据和目标数据\n",
    "# 创建输入数据和目标数据\n",
    "for i in range(0, len(trajectory) - window_size, step_size):\n",
    "    dataX.append(trajectory[i:i+window_size])\n",
    "    dataY.append(trajectory[i+window_size,1:3])\n",
    "\n",
    "# 将输入数据和目标数据转换为numpy数组\n",
    "dataX = np.array(dataX, dtype='float64')\n",
    "dataY = np.array(dataY, dtype='float64')\n",
    "# dataY = dataY.reshape(2408,1,2)\n",
    "print('dataX shape:', dataX.shape) # (91, 10, 3)\n",
    "print('dataY shape:', dataY.shape) # (91, 2)\n",
    "# 使用transpose()方法交换第二维度和第三维度\n",
    "dataX = dataX.transpose((0, 2, 1))\n",
    "print('dataX shape:', dataX.shape)\n",
    "train_x = dataX\n",
    "train_y= dataY\n",
    "print(train_x)\n",
    "print(train_y)\n",
    "x_data = train_x\n",
    "x_data = np.array(x_data)\n",
    "# x_data = x_data.reshape(19828,5,1)\n",
    "x_data.shape\n",
    "y_data = train_y\n",
    "\n",
    "y_data.shape\n",
    "# Preporcessing Normalizing Valuse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "# new_df= x_data.reshape(x_data.shape[0],5)\n",
    "x_data=x_data.reshape(2408,50)\n",
    "new_x_data = sc.fit_transform(x_data)\n",
    "new_x_data = new_x_data.reshape(2408,5,10)\n",
    "\n",
    "print('X_data shape :', x_data.shape)\n",
    "print('new X_data shape :', new_x_data.shape)\n",
    "\n",
    "\n",
    "# y_data=y_data.reshape(2408,2)\n",
    "new_y_data = sc.fit_transform(y_data)\n",
    "# new_y_data = new_y_data.reshape(2408,2)\n",
    "print('y_data shape :', y_data.shape)\n",
    "print('new y_data shape :', new_y_data.shape)\n",
    "# print(new_x_data)\n",
    "print(new_y_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(new_x_data, new_y_data, test_size=0.3, random_state=42)\n",
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "# model.add(LSTM(units=50, batch_input_shape=(None,5,10),return_sequences=True,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=50, batch_input_shape=(None,5,10),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# second layer\n",
    "# model.add(Dense(128, 1))\n",
    "# model.add(LSTM(units=100,return_sequences=True,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=100,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "# model.add(LSTM(units=50,return_sequences=False,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=50,return_sequences=False))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# fourth dense layer\n",
    "model.add(Dense(units=2))\n",
    "#不声明默认为0.001\n",
    "# adam = Adam(learning_rate=0.0015)#减小学习率：可以通过将优化器的learning_rate参数设置为一个较小的值来减小学习率。例如，可以将模型编译代码修改为：\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])#增加L2正则化项：将kernel_regularizer参数设置为regularizers.l2()，并指定相应的正则化系数。\n",
    "model.summary()\n",
    "\n",
    "# # 定义LSTM模型\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(10, 5)))\n",
    "# model.add(Dense(2))\n",
    "\n",
    "# # 编译模型\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.summary()\n",
    "'''\n",
    "# LSTM层的units数：增加units数可以增加模型的表达能力，但也会增加模型的复杂度和训练时间。因此，可以尝试不同的units数并找到一个合适的值。\n",
    "\n",
    "# Dropout层的比率：增加Dropout比率可以减少过拟合的风险，但过高的Dropout比率会影响模型的性能。因此，可以尝试不同的Dropout比率并找到一个合适的值。\n",
    "\n",
    "# 学习率(learning rate)：Adam优化器默认的学习率通常可以正常工作，但有时候需要手动调整学习率以加速或稳定训练过程。\n",
    "\n",
    "# 批量大小(batch size)：批量大小会影响模型的训练速度和内存占用情况。通常情况下，使用大批量大小可以加快训练速度，但也会占用更多的内存。\n",
    "\n",
    "# 训练轮数(epochs)：增加训练轮数可以提高模型的精度，但也会增加训练时间。可以使用早停法(early stopping)等技术来提高模型的训练效率。\n",
    " '''\n",
    "history = model.fit(x_train,y_train,epochs=50, batch_size=32,validation_data=(x_test,y_test))\n",
    "model.save(\"LSTM.h5\")\n",
    "model1 = load_model(\"LSTM.h5\")\n",
    "lstm_pred_train = model.predict(x_train)\n",
    "lstm_pred_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.83078887  0.8586852 ]\n",
      " [ 0.83080084  0.85865686]\n",
      " [-0.7127135  -0.41449657]\n",
      " ...\n",
      " [ 0.83091097  0.85838095]\n",
      " [ 0.83084657  0.85854482]\n",
      " [ 0.83083664  0.85856582]]\n"
     ]
    }
   ],
   "source": [
    "# 导入需要的库\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "# 原数据\n",
    "# x_train, x_test, y_train, y_test\n",
    "# 加载数据集和GRU、LSTM模型的预测结果\n",
    "\n",
    "\n",
    "# gru_pred_train = load_gru_pred_train()  # GRU模型的训练集预测结果 输出\n",
    "# gru_pred_test = load_gru_pred_test()    # GRU模型的测试集预测结果 输出\n",
    "\n",
    "# lstm_pred_train = load_lstm_pred_train()  # LSTM模型的训练集预测结果 输出\n",
    "# lstm_pred_test = load_lstm_pred_test()    # LSTM模型的测试集预测结果 输出\n",
    "x_train=x_train.reshape(-1,50)\n",
    "x_test=x_test.reshape(-1,50)\n",
    "\n",
    "# 将GRU和LSTM的预测结果作为特征融合在一起\n",
    "X_train = np.column_stack((x_train, gru_pred_train, lstm_pred_train))\n",
    "X_test = np.column_stack((x_test, gru_pred_test, lstm_pred_test))\n",
    "\n",
    "# 使用随机森林模型拟合数据\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = rf.predict(X_test)\n",
    "print(y_pred)\n",
    "# 评估模型\n",
    "# evaluation(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 2)\n",
      "[[679955.841303 419832.252971]\n",
      " [679955.8419   419832.244662]\n",
      " [679878.879265 419458.890953]\n",
      " ...\n",
      " [679955.847391 419832.163752]\n",
      " [679955.84418  419832.211807]\n",
      " [679955.843685 419832.217964]]\n"
     ]
    }
   ],
   "source": [
    "result= y_pred\n",
    "# # 设置打印选项，精度为3位小数\n",
    "# np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "res_df = sc.inverse_transform(result)\n",
    "# res_df.reshape(new_df.shape[0],5,1)\n",
    "res_df\n",
    "print(res_df.shape)\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413 419832.253 ]\n",
      " [679955.8419 419832.2448]\n",
      " [679878.8793 419458.8907]\n",
      " ...\n",
      " [679955.8474 419832.1637]\n",
      " [679955.844  419832.2116]\n",
      " [679955.8437 419832.2183]]\n",
      "(723, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.reshape (723, 2)  #需要改的地方\n",
    "# y_test_actual=sc.inverse_transform(y_test[2:3])\n",
    "y_test_actual=sc.inverse_transform(y_test)\n",
    "print(y_test_actual)\n",
    "print(y_test_actual.shape)\n",
    "# for i in range(len(result)):\n",
    "#     plt.scatter(result[0][i],result[1][i],c='r')\n",
    "#     plt.scatter(y_test[0][i],y_test[1][i],c='g')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制预测值和实际值\n",
    "\n",
    "predicted_df = pd.DataFrame(data=res_df[0:,0:],index=[i for i in range(res_df.shape[0])],columns=['f'+str(i) for i in range(res_df.shape[1])])\n",
    "\n",
    "actual_df = pd.DataFrame(data=y_test_actual[0:,0:],index=[i for i in range(y_test_actual.shape[0])],columns=['f'+str(i) for i in range(y_test_actual.shape[1])])\n",
    "\n",
    "# for i in range(len(res_df)):\n",
    "# #   print(i)\n",
    "plt.scatter(x=predicted_df['f0'],y=predicted_df['f1'],c='r',s=0.1,alpha=0.5)\n",
    "plt.scatter(x=actual_df['f0'],y=actual_df['f1'],c='b',s=0.1,alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06503064093554188\n",
      "MAE: 0.07038647925222284\n",
      "相关系数为： 0.9597269629903625\n",
      "R^2: 0.9999971810006703\n",
      "Correlation coefficient: 0.9597269629903625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# # 定义真实定位数据和预测数据\n",
    "# true_pos = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "# pred_pos = np.array([[0.5, 1.5], [3.2, 3.9], [4.9, 6.2]])\n",
    "\n",
    "# 计算均方误差\n",
    "mse = mean_squared_error(actual_df, predicted_df)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "# 计算平均绝对误差\n",
    "mae = mean_absolute_error(actual_df, predicted_df)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# 计算相关系数矩阵\n",
    "corr_matrix = np.corrcoef(actual_df.T, predicted_df.T)\n",
    "corr_coefficient = corr_matrix[0, 1] # 取出相关系数值\n",
    "print(\"相关系数为：\", corr_coefficient) # 打印相关系数\n",
    "# 计算决定系数\n",
    "r2 = r2_score(actual_df, predicted_df)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 将实际值和预测值分别存储在矩阵中\n",
    "actual_matrix = np.array(actual_df)\n",
    "predicted_matrix = np.array(predicted_df)\n",
    "correlation_matrix = np.corrcoef(actual_matrix, predicted_matrix, rowvar=False) # 计算相关系数（Pearson相关系数）\n",
    "correlation_coefficient = correlation_matrix[0, 1] # 提取相关系数矩阵中的相关系数\n",
    "print(\"Correlation coefficient:\", correlation_coefficient) # 打印相关系数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413   419832.253    679955.841303 419832.252971]\n",
      " [679955.8419   419832.2448   679955.8419   419832.244662]\n",
      " [679878.8793   419458.8907   679878.879265 419458.890953]\n",
      " ...\n",
      " [679955.8474   419832.1637   679955.847391 419832.163752]\n",
      " [679955.844    419832.2116   679955.84418  419832.211807]\n",
      " [679955.8437   419832.2183   679955.843685 419832.217964]]\n"
     ]
    }
   ],
   "source": [
    " #合并两个矩阵\n",
    "merged_matrix = np.concatenate((y_test_actual, res_df), axis=1)#真实,预测\n",
    "\n",
    "print(merged_matrix) # 输出合并后矩阵的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00002915 0.000138   0.00025541 0.04977691 0.         0.41486116\n",
      " 0.41352833 0.         0.         0.00035196 0.56760183 0.00076521\n",
      " 0.         0.00011635 0.85658119 0.00074135 1.19204489 0.00458024\n",
      " 0.03830963 0.00057359 0.         0.16085166 0.06152521 0.72677783\n",
      " 0.00008732 0.000194   0.00067394 0.87940005 0.         0.\n",
      " 0.00220329 0.00061747 0.14108731 0.         0.00118908 0.49130033\n",
      " 0.         1.308873   0.5226491  0.         0.00291183 0.43309148\n",
      " 0.00095079 0.95751589 0.00714951 0.35787246 0.13785566 1.55599036\n",
      " 0.         0.00259358 0.03691395 0.         0.06490798 0.0061788\n",
      " 0.69990955 0.0003803  1.4095707  0.77398477 0.00117253 0.01208006\n",
      " 1.61068976 0.00024731 1.39188179 0.00293104 0.00026522 0.00007043\n",
      " 0.00023044 0.33372178 0.00266461 0.00170036 0.         0.00620114\n",
      " 0.         0.00026063 0.         0.00057414 0.00198201 0.0018048\n",
      " 0.00122178 0.00203521 0.17068409 0.00033812 0.00198212 0.00048375\n",
      " 0.         0.00007026 0.00349421 0.49683211 2.24794885 1.10931656\n",
      " 0.00027302 0.37573723 0.04843827 1.37670674 0.00001825 0.76744962\n",
      " 0.00088586 0.00124052 0.         0.99745483 0.00075329 0.00139114\n",
      " 0.00006607 0.000153   0.1314053  0.00696342 0.24516454 0.08994815\n",
      " 0.00276658 0.00053237 0.00016674 0.00030254 0.00214214 0.00014237\n",
      " 0.00221778 0.00017114 0.00059315 0.         0.18904681 0.00154685\n",
      " 0.81362479 0.1293782  0.60230177 0.00061405 0.07572533 0.00006888\n",
      " 0.00010763 0.00055473 0.00015784 0.         0.00494375 0.14808579\n",
      " 1.08102443 0.0043407  0.63144349 0.00753793 0.         0.00150702\n",
      " 0.00009519 0.00017978 0.00088748 0.20709119 0.00082157 0.01365567\n",
      " 0.00058331 0.00059693 0.00011915 1.02926816 0.68073431 0.00099859\n",
      " 0.37705088 0.         0.         0.21306308 0.         0.33408903\n",
      " 0.00177704 0.00030513 0.96033882 0.00162813 0.00037747 0.00035945\n",
      " 0.00251382 0.00020393 0.23888349 0.000221   0.05719255 0.00092928\n",
      " 0.29431631 0.0000228  0.         0.00045064 0.00060615 0.\n",
      " 0.00275472 0.0000794  0.         0.         0.01465855 0.00027502\n",
      " 0.00013946 0.01138248 0.09420597 0.         0.00013054 0.00352927\n",
      " 0.40467392 0.00752464 0.06661647 0.00037449 0.00046409 0.3427306\n",
      " 0.00122786 0.         0.00216907 0.00026234 0.00050351 0.0002134\n",
      " 0.         0.00097011 0.00239532 0.00018728 0.00047515 0.\n",
      " 0.00100904 1.69692978 0.44579199 0.00074439 0.00151114 0.00032905\n",
      " 0.23439726 0.         0.00116341 0.00385332 0.00037263 0.\n",
      " 1.67594992 0.         0.00219899 1.74648597 1.25703146 0.00020014\n",
      " 0.00011293 0.00023608 0.         0.31643305 0.00111833 0.00122442\n",
      " 0.37092778 0.00026683 0.00050062 0.00086329 0.03294617 0.\n",
      " 0.         0.00009981 0.1617271  0.14480505 0.00040927 0.00131362\n",
      " 0.05205862 0.00065979 0.00083147 0.         0.00028865 0.00038805\n",
      " 0.00079771 0.00025121 0.00062694 0.00019839 0.00061224 0.43907683\n",
      " 0.00496193 0.02313328 0.0002147  0.00087297 0.04990539 0.00021633\n",
      " 0.00193641 0.14227775 0.         0.07682473 0.00148809 0.00044507\n",
      " 0.         0.00015101 0.00431483 0.00146323 1.69242985 0.00675232\n",
      " 0.2347123  0.00017677 0.00116303 0.15748309 0.00016867 0.\n",
      " 0.00046021 0.37843914 0.11673523 0.00192945 0.00426716 0.0002284\n",
      " 0.         0.00038687 0.00092649 0.         0.00001924 0.\n",
      " 0.00562602 0.00655295 0.00014703 0.00231456 0.00186135 0.07382365\n",
      " 0.00013025 0.00102306 0.09374533 0.00039741 0.         0.0002528\n",
      " 0.00007961 0.         0.         0.00002408 0.12451886 0.00009487\n",
      " 0.00718555 0.13781843 0.         0.000246   0.00029824 0.00019278\n",
      " 0.00023064 0.00017219 0.         0.         0.000227   0.00162766\n",
      " 0.00018386 0.357412   0.00433172 0.2758564  0.000098   0.00041751\n",
      " 0.00095219 0.0000902  0.00339346 0.75868597 0.01009775 0.45752602\n",
      " 0.000157   0.00044953 0.00491866 0.00029025 0.         0.00396281\n",
      " 0.4731254  0.00010867 0.         0.00404623 0.00032    0.000125\n",
      " 0.00033301 0.64466992 0.00211435 0.00171319 0.00002668 0.00015241\n",
      " 0.00034969 0.00023702 0.70487342 0.00230095 0.0539471  0.00104962\n",
      " 0.00514454 0.00266113 0.00059214 0.21713849 0.         0.00009374\n",
      " 0.43152204 0.0036162  0.00234846 0.         0.04208913 0.09943749\n",
      " 0.01701253 0.01172493 0.00032216 0.00040987 0.10974416 0.19101989\n",
      " 0.00098727 0.00016103 1.2421332  0.00125274 0.00765581 0.00214026\n",
      " 0.0001423  0.00158243 0.338347   0.00044765 0.00053065 0.00023431\n",
      " 0.00068181 0.00834003 0.00073834 0.         0.         0.00189325\n",
      " 0.29711672 0.00014712 0.         0.00267415 0.31260746 0.\n",
      " 0.00012618 0.04839254 0.         0.00026182 0.11746027 0.01389308\n",
      " 0.00088124 0.00068434 0.00381624 0.00273616 0.00130497 0.00230861\n",
      " 0.02592395 0.7539904  0.0036053  0.00027306 0.00224904 0.\n",
      " 0.00089396 0.00016059 0.00023691 0.26851802 0.00072551 0.75154941\n",
      " 0.         0.00011229 0.68046537 0.0012408  0.00023881 0.03966263\n",
      " 0.00010062 0.         0.00050692 0.00854675 0.00028956 0.38562627\n",
      " 0.52185116 0.0033034  0.000012   0.00147109 0.00003513 0.00958947\n",
      " 0.00498188 0.00214226 0.00234629 2.16876545 0.81041445 0.\n",
      " 0.00273458 0.10472447 0.000103   0.27072353 0.00031146 0.00389678\n",
      " 0.         0.00550416 0.00054813 0.000225   0.00042309 0.00002267\n",
      " 0.         0.00110187 0.         0.00019238 0.00095047 0.\n",
      " 0.00053355 0.         0.00148148 0.00053044 0.54226444 0.00442919\n",
      " 0.00054781 0.06203052 0.22425953 0.00510751 1.05059549 0.38002077\n",
      " 0.         0.         0.01850157 0.00021901 0.00013416 0.02180217\n",
      " 0.00268188 0.         0.37751308 0.00320873 0.00012332 0.00003905\n",
      " 1.56523172 0.00100992 0.0001307  0.00198297 0.00055404 0.\n",
      " 0.00010904 0.00254107 0.00022502 0.         0.11795605 0.00046472\n",
      " 0.00124944 0.00262476 0.         1.15442373 0.00126209 0.17379487\n",
      " 0.08803535 0.00251694 0.00166528 0.00023448 0.         0.00114551\n",
      " 0.00086341 0.05250447 0.00983598 0.00012397 2.85203231 0.00337055\n",
      " 0.00479818 0.         0.0327244  0.00040339 0.00004579 0.00002546\n",
      " 0.564197   0.04344343 0.00106329 0.02987991 0.16451636 0.48834683\n",
      " 1.42662023 0.00210028 0.00017925 0.06613592 0.         0.07353913\n",
      " 0.         0.         0.00117053 0.00087411 0.00037205 0.70850006\n",
      " 0.00399847 0.00033693 0.00231727 1.50290869 0.16131391 0.00061414\n",
      " 0.         0.         0.00029604 0.00168997 0.         0.00044659\n",
      " 0.00019809 0.02210517 0.00128746 0.         0.         0.\n",
      " 0.62544045 0.00146107 0.16412382 0.         0.03005965 0.00047134\n",
      " 0.04527067 0.         0.03319129 0.00017903 0.00019023 0.10016682\n",
      " 0.183346   0.00028514 0.         0.00008841 0.00239405 0.00085115\n",
      " 0.00204576 0.00123142 0.36286454 1.57494601 0.39895558 0.\n",
      " 0.00032711 0.         0.06458113 0.00096258 0.00099427 0.18176526\n",
      " 0.00029025 0.05744667 0.         0.00118111 0.00705373 0.75224983\n",
      " 0.00144931 0.01316626 0.09132172 1.51634776 0.67911064 0.00038227\n",
      " 0.00210945 0.00019812 0.00022235 0.09786438 0.3400942  0.\n",
      " 0.00151465 0.00029063 0.20991044 0.00022756 0.00025669 0.00002247\n",
      " 0.         0.00319079 0.00028349 0.00108843 0.00010207 0.00171149\n",
      " 0.00022902 0.00090382 0.0024348  0.05263105 0.         0.00023882\n",
      " 0.0001597  0.14158992 0.00173496 0.00050647 0.         0.00009205\n",
      " 0.00043352 0.         0.18375656 0.1329013  0.00036852 0.00018112\n",
      " 0.14931319 0.00095968 0.00021431 1.17383273 0.0003055  2.17147097\n",
      " 0.         0.00015814 0.00040066 0.00255602 0.00040854 0.03387287\n",
      " 0.00323957 0.         0.00012391 0.00322233 0.         0.00212556\n",
      " 0.0011957  0.         0.00042327 0.         0.         0.00022397\n",
      " 0.0013073  0.         0.00013909 0.000123   0.         0.00020093\n",
      " 0.         0.00118964 0.0008055  0.00020727 0.00051949 0.00024135\n",
      " 0.95068458 0.00016834 0.00029204 0.         0.36091151 0.00203528\n",
      " 0.00353673 0.00024307 0.00015603 0.06679706 0.00034172 0.00090431\n",
      " 0.00045309 0.00323064 0.36127368 0.00005077 0.00041942 0.00165362\n",
      " 0.         0.         0.         0.00099898 0.00549804 0.58414773\n",
      " 0.00009675 0.00037811 0.42061026 0.07474646 0.10702511 0.18894444\n",
      " 0.         0.00383764 0.00155863 0.00164192 0.04998741 0.00298736\n",
      " 0.         0.00041983 0.         0.00023719 0.00013494 0.\n",
      " 0.         0.000363   0.39863443 0.08488076 0.00009619 0.00236233\n",
      " 0.00005277 0.00027432 0.00033633]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 计算每行数据中两个点之间的欧式距离\n",
    "distances = np.linalg.norm(merged_matrix[:, :2] - merged_matrix[:, 2:], axis=1)\n",
    "print(distances)\n",
    "np.savetxt('distances.txt', distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
