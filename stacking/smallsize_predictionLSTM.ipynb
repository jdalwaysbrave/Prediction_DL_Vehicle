{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)  # 关闭科学计数法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_csv = pd.read_csv(\"./filtered.csv\")#读取filtered file\n",
    "trajectory = np.array(data_csv, dtype=np.float64)  # trajectory1[:, 2:9] 原为2个数据 现为8个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataX shape: (2408, 10, 5)\n",
      "dataY shape: (2408, 2)\n",
      "dataX shape: (2408, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "dataX, dataY = [], []\n",
    "    # 定义滑动窗口的大小和步长\n",
    "window_size = 10\n",
    "step_size = 1\n",
    "\n",
    " # 创建输入数据和目标数据\n",
    "\n",
    "    # 创建输入数据和目标数据\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(trajectory) - window_size, step_size):\n",
    "    dataX.append(trajectory[i:i+window_size])\n",
    "    dataY.append(trajectory[i+window_size,1:3])\n",
    "\n",
    " # 将输入数据和目标数据转换为numpy数组\n",
    "dataX = np.array(dataX, dtype='float64')\n",
    "dataY = np.array(dataY, dtype='float64')\n",
    "# dataY = dataY.reshape(2408,1,2)\n",
    "print('dataX shape:', dataX.shape) # (91, 10, 3)\n",
    "print('dataY shape:', dataY.shape) # (91, 2)\n",
    "# 使用transpose()方法交换第二维度和第三维度\n",
    "dataX = dataX.transpose((0, 2, 1))\n",
    "print('dataX shape:', dataX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance based on haversine and time difference\n",
    "# convert time to seconds\n",
    "\n",
    "train_x = dataX\n",
    "train_y= dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[     0.          1.          2.     ...      7.          8.\n",
      "        9.    ]\n",
      "  [679864.4007 679864.4159 679864.4315 ... 679864.5083 679864.5238\n",
      "   679864.5391]\n",
      "  [419283.8057 419284.144  419284.4826 ... 419286.1755 419286.5141\n",
      "   419286.8528]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     1.          2.          3.     ...      8.          9.\n",
      "       10.    ]\n",
      "  [679864.4159 679864.4315 679864.4467 ... 679864.5238 679864.5391\n",
      "   679864.5546]\n",
      "  [419284.144  419284.4826 419284.8213 ... 419286.5141 419286.8528\n",
      "   419287.1914]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[     2.          3.          4.     ...      9.         10.\n",
      "       11.    ]\n",
      "  [679864.4315 679864.4467 679864.4623 ... 679864.5391 679864.5546\n",
      "   679864.5699]\n",
      "  [419284.4826 419284.8213 419285.1599 ... 419286.8528 419287.1914\n",
      "   419287.53  ]\n",
      "  [    11.12       11.12       11.12   ...     11.12       11.12\n",
      "       11.12  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  2405.       2406.       2407.     ...   2412.       2413.\n",
      "     2414.    ]\n",
      "  [679949.3305 679949.1406 679948.9507 ... 679948.0009 679947.811\n",
      "   679947.6212]\n",
      "  [419863.8233 419864.646  419865.4683 ... 419869.581  419870.4036\n",
      "   419871.226 ]\n",
      "  [    27.74       27.7        27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.38       -0.19        0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2406.       2407.       2408.     ...   2413.       2414.\n",
      "     2415.    ]\n",
      "  [679949.1406 679948.9507 679948.7608 ... 679947.811  679947.6212\n",
      "   679947.4313]\n",
      "  [419864.646  419865.4683 419866.291  ... 419870.4036 419871.226\n",
      "   419872.0486]\n",
      "  [    27.7        27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [    -0.19        0.          0.     ...      0.          0.\n",
      "        0.    ]]\n",
      "\n",
      " [[  2407.       2408.       2409.     ...   2414.       2415.\n",
      "     2416.    ]\n",
      "  [679948.9507 679948.7608 679948.5709 ... 679947.6212 679947.4313\n",
      "   679947.2414]\n",
      "  [419865.4683 419866.291  419867.1133 ... 419871.226  419872.0486\n",
      "   419872.871 ]\n",
      "  [    27.69       27.69       27.69   ...     27.69       27.69\n",
      "       27.69  ]\n",
      "  [     0.          0.          0.     ...      0.          0.\n",
      "        0.    ]]]\n",
      "[[679864.5546 419287.1914]\n",
      " [679864.5699 419287.53  ]\n",
      " [679864.5854 419287.8687]\n",
      " ...\n",
      " [679947.4313 419872.0486]\n",
      " [679947.2414 419872.871 ]\n",
      " [679947.0515 419873.6937]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408, 5, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# convert pandas dataframe to numpy array\n",
    "\n",
    "x_data = train_x\n",
    "x_data = np.array(x_data)\n",
    "# x_data = x_data.reshape(19828,5,1)\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Too Much Slow Step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2408, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = train_y\n",
    "\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape : (2408, 50)\n",
      "new X_data shape : (2408, 5, 10)\n",
      "y_data shape : (2408, 2)\n",
      "new y_data shape : (2408, 2)\n",
      "[[-1.         -1.        ]\n",
      " [-0.99969315 -0.99884536]\n",
      " [-0.99938229 -0.99769038]\n",
      " ...\n",
      " [ 0.66212312  0.99439013]\n",
      " [ 0.65831461  0.99719455]\n",
      " [ 0.65450609  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Preporcessing Normalizing Valuse\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "# new_df= x_data.reshape(x_data.shape[0],5)\n",
    "x_data=x_data.reshape(2408,50)\n",
    "new_x_data = sc.fit_transform(x_data)\n",
    "new_x_data = new_x_data.reshape(2408,5,10)\n",
    "\n",
    "print('X_data shape :', x_data.shape)\n",
    "print('new X_data shape :', new_x_data.shape)\n",
    "\n",
    "\n",
    "# y_data=y_data.reshape(2408,2)\n",
    "new_y_data = sc.fit_transform(y_data)\n",
    "# new_y_data = new_y_data.reshape(2408,2)\n",
    "print('y_data shape :', y_data.shape)\n",
    "print('new y_data shape :', new_y_data.shape)\n",
    "# print(new_x_data)\n",
    "print(new_y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM,RNN\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(new_x_data, new_y_data, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1685, 5, 10)\n",
      "(1685, 2)\n",
      "(723, 5, 10)\n",
      "(723, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_27 (LSTM)               (None, 5, 50)             12200     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 5, 50)             0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 5, 100)            60400     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 5, 100)            0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 102,902\n",
      "Trainable params: 102,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# LSTM层的units数：增加units数可以增加模型的表达能力，但也会增加模型的复杂度和训练时间。因此，可以尝试不同的units数并找到一个合适的值。\\n\\n# Dropout层的比率：增加Dropout比率可以减少过拟合的风险，但过高的Dropout比率会影响模型的性能。因此，可以尝试不同的Dropout比率并找到一个合适的值。\\n\\n# 学习率(learning rate)：Adam优化器默认的学习率通常可以正常工作，但有时候需要手动调整学习率以加速或稳定训练过程。\\n\\n# 批量大小(batch size)：批量大小会影响模型的训练速度和内存占用情况。通常情况下，使用大批量大小可以加快训练速度，但也会占用更多的内存。\\n\\n# 训练轮数(epochs)：增加训练轮数可以提高模型的精度，但也会增加训练时间。可以使用早停法(early stopping)等技术来提高模型的训练效率。\\n '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "# model.add(LSTM(units=50, batch_input_shape=(None,5,10),return_sequences=True,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=50, batch_input_shape=(None,5,10),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# second layer\n",
    "# model.add(Dense(128, 1))\n",
    "# model.add(LSTM(units=100,return_sequences=True,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=100,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# third layer\n",
    "# model.add(LSTM(units=50,return_sequences=False,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(LSTM(units=50,return_sequences=False))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# fourth dense layer\n",
    "model.add(Dense(units=2))\n",
    "#不声明默认为0.001\n",
    "# adam = Adam(learning_rate=0.0015)#减小学习率：可以通过将优化器的learning_rate参数设置为一个较小的值来减小学习率。例如，可以将模型编译代码修改为：\n",
    "\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])#增加L2正则化项：将kernel_regularizer参数设置为regularizers.l2()，并指定相应的正则化系数。\n",
    "model.summary()\n",
    "\n",
    "# # 定义LSTM模型\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(64, input_shape=(10, 5)))\n",
    "# model.add(Dense(2))\n",
    "\n",
    "# # 编译模型\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.summary()\n",
    "'''\n",
    "# LSTM层的units数：增加units数可以增加模型的表达能力，但也会增加模型的复杂度和训练时间。因此，可以尝试不同的units数并找到一个合适的值。\n",
    "\n",
    "# Dropout层的比率：增加Dropout比率可以减少过拟合的风险，但过高的Dropout比率会影响模型的性能。因此，可以尝试不同的Dropout比率并找到一个合适的值。\n",
    "\n",
    "# 学习率(learning rate)：Adam优化器默认的学习率通常可以正常工作，但有时候需要手动调整学习率以加速或稳定训练过程。\n",
    "\n",
    "# 批量大小(batch size)：批量大小会影响模型的训练速度和内存占用情况。通常情况下，使用大批量大小可以加快训练速度，但也会占用更多的内存。\n",
    "\n",
    "# 训练轮数(epochs)：增加训练轮数可以提高模型的精度，但也会增加训练时间。可以使用早停法(early stopping)等技术来提高模型的训练效率。\n",
    " '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 [==============================] - 8s 35ms/step - loss: 0.2617 - accuracy: 0.7009 - val_loss: 0.1062 - val_accuracy: 0.9267\n",
      "Epoch 2/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1250 - accuracy: 0.7674 - val_loss: 0.0833 - val_accuracy: 0.8354\n",
      "Epoch 3/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1175 - accuracy: 0.7525 - val_loss: 0.0903 - val_accuracy: 0.9474\n",
      "Epoch 4/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.1171 - accuracy: 0.7620 - val_loss: 0.0810 - val_accuracy: 0.7621\n",
      "Epoch 5/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1144 - accuracy: 0.7917 - val_loss: 0.0855 - val_accuracy: 0.7690\n",
      "Epoch 6/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.1095 - accuracy: 0.8030 - val_loss: 0.0944 - val_accuracy: 0.9627\n",
      "Epoch 7/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1061 - accuracy: 0.8047 - val_loss: 0.0829 - val_accuracy: 0.8866\n",
      "Epoch 8/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1041 - accuracy: 0.8012 - val_loss: 0.0705 - val_accuracy: 0.9682\n",
      "Epoch 9/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.1017 - accuracy: 0.8344 - val_loss: 0.0733 - val_accuracy: 0.9654\n",
      "Epoch 10/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0941 - accuracy: 0.8160 - val_loss: 0.0666 - val_accuracy: 0.9488\n",
      "Epoch 11/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0907 - accuracy: 0.8107 - val_loss: 0.0629 - val_accuracy: 0.8548\n",
      "Epoch 12/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0831 - accuracy: 0.8166 - val_loss: 0.0558 - val_accuracy: 0.9931\n",
      "Epoch 13/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0801 - accuracy: 0.8237 - val_loss: 0.0463 - val_accuracy: 0.8409\n",
      "Epoch 14/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0785 - accuracy: 0.8463 - val_loss: 0.0459 - val_accuracy: 0.9848\n",
      "Epoch 15/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0738 - accuracy: 0.8303 - val_loss: 0.0461 - val_accuracy: 0.8755\n",
      "Epoch 16/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0710 - accuracy: 0.8196 - val_loss: 0.0353 - val_accuracy: 0.7635\n",
      "Epoch 17/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0722 - accuracy: 0.8291 - val_loss: 0.0368 - val_accuracy: 0.9405\n",
      "Epoch 18/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0673 - accuracy: 0.8546 - val_loss: 0.0271 - val_accuracy: 0.8769\n",
      "Epoch 19/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0669 - accuracy: 0.8380 - val_loss: 0.0351 - val_accuracy: 0.9046\n",
      "Epoch 20/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0665 - accuracy: 0.8433 - val_loss: 0.0367 - val_accuracy: 0.8506\n",
      "Epoch 21/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.8409 - val_loss: 0.0319 - val_accuracy: 0.9212\n",
      "Epoch 22/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0609 - accuracy: 0.8469 - val_loss: 0.0227 - val_accuracy: 0.9737\n",
      "Epoch 23/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.8439 - val_loss: 0.0225 - val_accuracy: 0.8686\n",
      "Epoch 24/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0620 - accuracy: 0.8487 - val_loss: 0.0412 - val_accuracy: 0.9281\n",
      "Epoch 25/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0599 - accuracy: 0.8374 - val_loss: 0.0438 - val_accuracy: 0.8990\n",
      "Epoch 26/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0595 - accuracy: 0.8356 - val_loss: 0.0176 - val_accuracy: 0.9544\n",
      "Epoch 27/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0586 - accuracy: 0.8493 - val_loss: 0.0231 - val_accuracy: 0.8866\n",
      "Epoch 28/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0602 - accuracy: 0.8261 - val_loss: 0.0336 - val_accuracy: 0.9502\n",
      "Epoch 29/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0587 - accuracy: 0.8409 - val_loss: 0.0216 - val_accuracy: 0.7953\n",
      "Epoch 30/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0563 - accuracy: 0.8463 - val_loss: 0.0289 - val_accuracy: 0.9931\n",
      "Epoch 31/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0567 - accuracy: 0.8849 - val_loss: 0.0299 - val_accuracy: 0.9972\n",
      "Epoch 32/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0561 - accuracy: 0.8748 - val_loss: 0.0189 - val_accuracy: 0.9959\n",
      "Epoch 33/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0578 - accuracy: 0.8866 - val_loss: 0.0225 - val_accuracy: 0.8852\n",
      "Epoch 34/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0575 - accuracy: 0.8546 - val_loss: 0.0274 - val_accuracy: 0.9986\n",
      "Epoch 35/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0550 - accuracy: 0.8665 - val_loss: 0.0236 - val_accuracy: 0.9986\n",
      "Epoch 36/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0547 - accuracy: 0.8861 - val_loss: 0.0227 - val_accuracy: 0.9931\n",
      "Epoch 37/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0541 - accuracy: 0.8831 - val_loss: 0.0406 - val_accuracy: 0.9986\n",
      "Epoch 38/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0549 - accuracy: 0.8635 - val_loss: 0.0209 - val_accuracy: 0.9986\n",
      "Epoch 39/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0540 - accuracy: 0.8914 - val_loss: 0.0254 - val_accuracy: 0.9972\n",
      "Epoch 40/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0547 - accuracy: 0.8611 - val_loss: 0.0246 - val_accuracy: 0.9972\n",
      "Epoch 41/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0546 - accuracy: 0.8819 - val_loss: 0.0159 - val_accuracy: 0.9972\n",
      "Epoch 42/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0531 - accuracy: 0.8878 - val_loss: 0.0129 - val_accuracy: 0.9986\n",
      "Epoch 43/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0533 - accuracy: 0.8902 - val_loss: 0.0166 - val_accuracy: 0.9986\n",
      "Epoch 44/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0538 - accuracy: 0.8748 - val_loss: 0.0154 - val_accuracy: 0.9959\n",
      "Epoch 45/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0536 - accuracy: 0.8795 - val_loss: 0.0161 - val_accuracy: 0.9986\n",
      "Epoch 46/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0525 - accuracy: 0.8730 - val_loss: 0.0181 - val_accuracy: 0.9931\n",
      "Epoch 47/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0537 - accuracy: 0.8938 - val_loss: 0.0161 - val_accuracy: 0.9972\n",
      "Epoch 48/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0530 - accuracy: 0.8950 - val_loss: 0.0267 - val_accuracy: 0.9986\n",
      "Epoch 49/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0531 - accuracy: 0.8914 - val_loss: 0.0185 - val_accuracy: 0.9903\n",
      "Epoch 50/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0517 - accuracy: 0.8997 - val_loss: 0.0194 - val_accuracy: 0.9972\n",
      "Epoch 51/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0507 - accuracy: 0.8890 - val_loss: 0.0215 - val_accuracy: 0.9986\n",
      "Epoch 52/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0505 - accuracy: 0.8694 - val_loss: 0.0169 - val_accuracy: 0.9972\n",
      "Epoch 53/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0518 - accuracy: 0.8801 - val_loss: 0.0286 - val_accuracy: 0.9959\n",
      "Epoch 54/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0512 - accuracy: 0.8944 - val_loss: 0.0201 - val_accuracy: 0.9779\n",
      "Epoch 55/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.8890 - val_loss: 0.0182 - val_accuracy: 0.9972\n",
      "Epoch 56/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0498 - accuracy: 0.8938 - val_loss: 0.0247 - val_accuracy: 0.8119\n",
      "Epoch 57/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0532 - accuracy: 0.8742 - val_loss: 0.0181 - val_accuracy: 0.9986\n",
      "Epoch 58/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0516 - accuracy: 0.8967 - val_loss: 0.0145 - val_accuracy: 0.9972\n",
      "Epoch 59/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0505 - accuracy: 0.8766 - val_loss: 0.0167 - val_accuracy: 0.9986\n",
      "Epoch 60/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0510 - accuracy: 0.8950 - val_loss: 0.0267 - val_accuracy: 0.9972\n",
      "Epoch 61/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0498 - accuracy: 0.8825 - val_loss: 0.0197 - val_accuracy: 0.9862\n",
      "Epoch 62/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0502 - accuracy: 0.8944 - val_loss: 0.0248 - val_accuracy: 0.9917\n",
      "Epoch 63/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0498 - accuracy: 0.8582 - val_loss: 0.0160 - val_accuracy: 0.9986\n",
      "Epoch 64/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0497 - accuracy: 0.8831 - val_loss: 0.0144 - val_accuracy: 0.9281\n",
      "Epoch 65/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0503 - accuracy: 0.8623 - val_loss: 0.0161 - val_accuracy: 0.9945\n",
      "Epoch 66/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0495 - accuracy: 0.8849 - val_loss: 0.0169 - val_accuracy: 0.9972\n",
      "Epoch 67/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0516 - accuracy: 0.8641 - val_loss: 0.0146 - val_accuracy: 0.9986\n",
      "Epoch 68/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0495 - accuracy: 0.8712 - val_loss: 0.0140 - val_accuracy: 0.9959\n",
      "Epoch 69/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0490 - accuracy: 0.8914 - val_loss: 0.0109 - val_accuracy: 0.9959\n",
      "Epoch 70/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0489 - accuracy: 0.8700 - val_loss: 0.0151 - val_accuracy: 0.9972\n",
      "Epoch 71/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0481 - accuracy: 0.8855 - val_loss: 0.0185 - val_accuracy: 0.9959\n",
      "Epoch 72/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0505 - accuracy: 0.8599 - val_loss: 0.0227 - val_accuracy: 0.9972\n",
      "Epoch 73/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0511 - accuracy: 0.8843 - val_loss: 0.0173 - val_accuracy: 0.9959\n",
      "Epoch 74/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0498 - accuracy: 0.8694 - val_loss: 0.0199 - val_accuracy: 0.9834\n",
      "Epoch 75/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0480 - accuracy: 0.8944 - val_loss: 0.0131 - val_accuracy: 0.9959\n",
      "Epoch 76/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0474 - accuracy: 0.8777 - val_loss: 0.0186 - val_accuracy: 0.9959\n",
      "Epoch 77/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0495 - accuracy: 0.8694 - val_loss: 0.0180 - val_accuracy: 0.9834\n",
      "Epoch 78/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0464 - accuracy: 0.8902 - val_loss: 0.0203 - val_accuracy: 0.9959\n",
      "Epoch 79/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0488 - accuracy: 0.8884 - val_loss: 0.0253 - val_accuracy: 0.9903\n",
      "Epoch 80/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0477 - accuracy: 0.8807 - val_loss: 0.0176 - val_accuracy: 0.9959\n",
      "Epoch 81/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0465 - accuracy: 0.8760 - val_loss: 0.0130 - val_accuracy: 0.9931\n",
      "Epoch 82/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0471 - accuracy: 0.8724 - val_loss: 0.0112 - val_accuracy: 0.9959\n",
      "Epoch 83/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0472 - accuracy: 0.8855 - val_loss: 0.0213 - val_accuracy: 0.8866\n",
      "Epoch 84/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0479 - accuracy: 0.8564 - val_loss: 0.0179 - val_accuracy: 0.9959\n",
      "Epoch 85/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0480 - accuracy: 0.8760 - val_loss: 0.0175 - val_accuracy: 0.9834\n",
      "Epoch 86/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0459 - accuracy: 0.8807 - val_loss: 0.0148 - val_accuracy: 0.8105\n",
      "Epoch 87/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0481 - accuracy: 0.8819 - val_loss: 0.0214 - val_accuracy: 0.9972\n",
      "Epoch 88/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0491 - accuracy: 0.8688 - val_loss: 0.0140 - val_accuracy: 0.9986\n",
      "Epoch 89/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0449 - accuracy: 0.8772 - val_loss: 0.0169 - val_accuracy: 0.9972\n",
      "Epoch 90/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0468 - accuracy: 0.8914 - val_loss: 0.0189 - val_accuracy: 0.9931\n",
      "Epoch 91/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0460 - accuracy: 0.8754 - val_loss: 0.0148 - val_accuracy: 0.9972\n",
      "Epoch 92/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0483 - accuracy: 0.8926 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
      "Epoch 93/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0470 - accuracy: 0.8855 - val_loss: 0.0130 - val_accuracy: 0.9972\n",
      "Epoch 94/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0451 - accuracy: 0.8967 - val_loss: 0.0147 - val_accuracy: 0.9848\n",
      "Epoch 95/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0465 - accuracy: 0.8920 - val_loss: 0.0162 - val_accuracy: 0.9903\n",
      "Epoch 96/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0455 - accuracy: 0.8825 - val_loss: 0.0142 - val_accuracy: 0.9959\n",
      "Epoch 97/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0474 - accuracy: 0.8908 - val_loss: 0.0123 - val_accuracy: 0.9959\n",
      "Epoch 98/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.8588 - val_loss: 0.0190 - val_accuracy: 0.9889\n",
      "Epoch 99/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.8938 - val_loss: 0.0166 - val_accuracy: 0.9931\n",
      "Epoch 100/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.8801 - val_loss: 0.0145 - val_accuracy: 0.9986\n",
      "Epoch 101/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0456 - accuracy: 0.8499 - val_loss: 0.0265 - val_accuracy: 0.9945\n",
      "Epoch 102/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.8825 - val_loss: 0.0102 - val_accuracy: 0.9876\n",
      "Epoch 103/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0470 - accuracy: 0.8896 - val_loss: 0.0212 - val_accuracy: 0.9834\n",
      "Epoch 104/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0465 - accuracy: 0.8748 - val_loss: 0.0105 - val_accuracy: 0.9959\n",
      "Epoch 105/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0460 - accuracy: 0.8712 - val_loss: 0.0117 - val_accuracy: 0.9931\n",
      "Epoch 106/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0461 - accuracy: 0.8896 - val_loss: 0.0174 - val_accuracy: 0.9889\n",
      "Epoch 107/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0462 - accuracy: 0.8926 - val_loss: 0.0148 - val_accuracy: 0.9903\n",
      "Epoch 108/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0457 - accuracy: 0.8866 - val_loss: 0.0164 - val_accuracy: 0.9931\n",
      "Epoch 109/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0442 - accuracy: 0.8825 - val_loss: 0.0135 - val_accuracy: 0.9959\n",
      "Epoch 110/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0453 - accuracy: 0.8938 - val_loss: 0.0158 - val_accuracy: 0.9945\n",
      "Epoch 111/200\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0456 - accuracy: 0.8754 - val_loss: 0.0129 - val_accuracy: 0.8562\n",
      "Epoch 112/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0466 - accuracy: 0.8795 - val_loss: 0.0115 - val_accuracy: 0.9986\n",
      "Epoch 113/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0460 - accuracy: 0.8825 - val_loss: 0.0207 - val_accuracy: 0.9876\n",
      "Epoch 114/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0478 - accuracy: 0.8837 - val_loss: 0.0218 - val_accuracy: 0.9931\n",
      "Epoch 115/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0475 - accuracy: 0.8742 - val_loss: 0.0106 - val_accuracy: 0.9959\n",
      "Epoch 116/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.0456 - accuracy: 0.8700 - val_loss: 0.0137 - val_accuracy: 0.9876\n",
      "Epoch 117/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0452 - accuracy: 0.8843 - val_loss: 0.0222 - val_accuracy: 0.9862\n",
      "Epoch 118/200\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.0457 - accuracy: 0.8718 - val_loss: 0.0147 - val_accuracy: 0.9862\n",
      "Epoch 119/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0460 - accuracy: 0.8736 - val_loss: 0.0155 - val_accuracy: 0.9876\n",
      "Epoch 120/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0437 - accuracy: 0.8682 - val_loss: 0.0106 - val_accuracy: 0.9945\n",
      "Epoch 121/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0465 - accuracy: 0.8908 - val_loss: 0.0124 - val_accuracy: 0.9876\n",
      "Epoch 122/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0438 - accuracy: 0.8694 - val_loss: 0.0192 - val_accuracy: 0.7967\n",
      "Epoch 123/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0460 - accuracy: 0.8641 - val_loss: 0.0107 - val_accuracy: 0.9903\n",
      "Epoch 124/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0447 - accuracy: 0.8694 - val_loss: 0.0144 - val_accuracy: 0.9903\n",
      "Epoch 125/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0457 - accuracy: 0.8783 - val_loss: 0.0135 - val_accuracy: 0.9295\n",
      "Epoch 126/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0448 - accuracy: 0.8682 - val_loss: 0.0157 - val_accuracy: 0.9931\n",
      "Epoch 127/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0443 - accuracy: 0.8682 - val_loss: 0.0141 - val_accuracy: 0.9945\n",
      "Epoch 128/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0437 - accuracy: 0.8736 - val_loss: 0.0178 - val_accuracy: 0.9917\n",
      "Epoch 129/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.8611 - val_loss: 0.0158 - val_accuracy: 0.9391\n",
      "Epoch 130/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0451 - accuracy: 0.8564 - val_loss: 0.0170 - val_accuracy: 0.9931\n",
      "Epoch 131/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0458 - accuracy: 0.8712 - val_loss: 0.0170 - val_accuracy: 0.9986\n",
      "Epoch 132/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0459 - accuracy: 0.8552 - val_loss: 0.0097 - val_accuracy: 0.9972\n",
      "Epoch 133/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0464 - accuracy: 0.8599 - val_loss: 0.0213 - val_accuracy: 0.9959\n",
      "Epoch 134/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.8736 - val_loss: 0.0114 - val_accuracy: 0.9917\n",
      "Epoch 135/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.8694 - val_loss: 0.0152 - val_accuracy: 0.9640\n",
      "Epoch 136/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0450 - accuracy: 0.8588 - val_loss: 0.0145 - val_accuracy: 0.9876\n",
      "Epoch 137/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0428 - accuracy: 0.8677 - val_loss: 0.0127 - val_accuracy: 0.9917\n",
      "Epoch 138/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0445 - accuracy: 0.8700 - val_loss: 0.0167 - val_accuracy: 0.9959\n",
      "Epoch 139/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0458 - accuracy: 0.8795 - val_loss: 0.0121 - val_accuracy: 0.9959\n",
      "Epoch 140/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0463 - accuracy: 0.8730 - val_loss: 0.0151 - val_accuracy: 0.9834\n",
      "Epoch 141/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.8694 - val_loss: 0.0098 - val_accuracy: 0.9903\n",
      "Epoch 142/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.8593 - val_loss: 0.0130 - val_accuracy: 0.9945\n",
      "Epoch 143/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.8659 - val_loss: 0.0139 - val_accuracy: 0.9931\n",
      "Epoch 144/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0432 - accuracy: 0.8724 - val_loss: 0.0113 - val_accuracy: 0.9931\n",
      "Epoch 145/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0427 - accuracy: 0.8451 - val_loss: 0.0193 - val_accuracy: 0.9931\n",
      "Epoch 146/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0453 - accuracy: 0.8700 - val_loss: 0.0154 - val_accuracy: 0.9959\n",
      "Epoch 147/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0443 - accuracy: 0.8807 - val_loss: 0.0185 - val_accuracy: 0.9931\n",
      "Epoch 148/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0435 - accuracy: 0.8653 - val_loss: 0.0087 - val_accuracy: 0.9931\n",
      "Epoch 149/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0436 - accuracy: 0.8647 - val_loss: 0.0175 - val_accuracy: 0.9931\n",
      "Epoch 150/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0439 - accuracy: 0.8706 - val_loss: 0.0108 - val_accuracy: 0.9972\n",
      "Epoch 151/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0433 - accuracy: 0.8730 - val_loss: 0.0106 - val_accuracy: 0.9945\n",
      "Epoch 152/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0461 - accuracy: 0.8766 - val_loss: 0.0211 - val_accuracy: 0.9959\n",
      "Epoch 153/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0440 - accuracy: 0.8677 - val_loss: 0.0147 - val_accuracy: 0.9903\n",
      "Epoch 154/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0445 - accuracy: 0.8481 - val_loss: 0.0095 - val_accuracy: 0.9931\n",
      "Epoch 155/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0441 - accuracy: 0.8659 - val_loss: 0.0124 - val_accuracy: 0.9848\n",
      "Epoch 156/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0426 - accuracy: 0.8736 - val_loss: 0.0097 - val_accuracy: 0.9917\n",
      "Epoch 157/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0436 - accuracy: 0.8855 - val_loss: 0.0161 - val_accuracy: 0.9945\n",
      "Epoch 158/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0438 - accuracy: 0.8742 - val_loss: 0.0129 - val_accuracy: 0.9889\n",
      "Epoch 159/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0432 - accuracy: 0.8884 - val_loss: 0.0148 - val_accuracy: 0.9917\n",
      "Epoch 160/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.8617 - val_loss: 0.0153 - val_accuracy: 0.9945\n",
      "Epoch 161/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0429 - accuracy: 0.8789 - val_loss: 0.0191 - val_accuracy: 0.9959\n",
      "Epoch 162/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.8712 - val_loss: 0.0151 - val_accuracy: 0.9945\n",
      "Epoch 163/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0437 - accuracy: 0.8659 - val_loss: 0.0121 - val_accuracy: 0.9959\n",
      "Epoch 164/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0434 - accuracy: 0.8599 - val_loss: 0.0146 - val_accuracy: 0.9945\n",
      "Epoch 165/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0455 - accuracy: 0.8516 - val_loss: 0.0157 - val_accuracy: 0.9959\n",
      "Epoch 166/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0414 - accuracy: 0.8599 - val_loss: 0.0153 - val_accuracy: 0.9820\n",
      "Epoch 167/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0428 - accuracy: 0.8688 - val_loss: 0.0118 - val_accuracy: 0.9931\n",
      "Epoch 168/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0423 - accuracy: 0.8605 - val_loss: 0.0108 - val_accuracy: 0.9931\n",
      "Epoch 169/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0422 - accuracy: 0.8582 - val_loss: 0.0110 - val_accuracy: 0.9945\n",
      "Epoch 170/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0432 - accuracy: 0.8647 - val_loss: 0.0155 - val_accuracy: 0.9945\n",
      "Epoch 171/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0428 - accuracy: 0.8510 - val_loss: 0.0129 - val_accuracy: 0.9972\n",
      "Epoch 172/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0431 - accuracy: 0.8694 - val_loss: 0.0084 - val_accuracy: 0.9917\n",
      "Epoch 173/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0424 - accuracy: 0.8611 - val_loss: 0.0120 - val_accuracy: 0.8921\n",
      "Epoch 174/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0437 - accuracy: 0.8510 - val_loss: 0.0116 - val_accuracy: 0.9917\n",
      "Epoch 175/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0432 - accuracy: 0.8623 - val_loss: 0.0160 - val_accuracy: 0.9945\n",
      "Epoch 176/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0418 - accuracy: 0.8677 - val_loss: 0.0073 - val_accuracy: 0.9959\n",
      "Epoch 177/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.8451 - val_loss: 0.0126 - val_accuracy: 0.9945\n",
      "Epoch 178/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0429 - accuracy: 0.8647 - val_loss: 0.0128 - val_accuracy: 0.9820\n",
      "Epoch 179/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0423 - accuracy: 0.8730 - val_loss: 0.0140 - val_accuracy: 0.7953\n",
      "Epoch 180/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.8487 - val_loss: 0.0147 - val_accuracy: 0.7953\n",
      "Epoch 181/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0444 - accuracy: 0.8564 - val_loss: 0.0164 - val_accuracy: 0.9945\n",
      "Epoch 182/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0439 - accuracy: 0.8766 - val_loss: 0.0140 - val_accuracy: 0.9336\n",
      "Epoch 183/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0426 - accuracy: 0.8706 - val_loss: 0.0104 - val_accuracy: 0.9945\n",
      "Epoch 184/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0424 - accuracy: 0.8665 - val_loss: 0.0090 - val_accuracy: 0.9972\n",
      "Epoch 185/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0423 - accuracy: 0.8576 - val_loss: 0.0113 - val_accuracy: 0.9889\n",
      "Epoch 186/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0432 - accuracy: 0.8558 - val_loss: 0.0132 - val_accuracy: 0.9931\n",
      "Epoch 187/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0420 - accuracy: 0.8516 - val_loss: 0.0214 - val_accuracy: 0.9848\n",
      "Epoch 188/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.8688 - val_loss: 0.0114 - val_accuracy: 0.9917\n",
      "Epoch 189/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0435 - accuracy: 0.8599 - val_loss: 0.0098 - val_accuracy: 0.9945\n",
      "Epoch 190/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0421 - accuracy: 0.8522 - val_loss: 0.0135 - val_accuracy: 0.9972\n",
      "Epoch 191/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0430 - accuracy: 0.8611 - val_loss: 0.0116 - val_accuracy: 0.7953\n",
      "Epoch 192/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0420 - accuracy: 0.8605 - val_loss: 0.0144 - val_accuracy: 0.8050\n",
      "Epoch 193/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0434 - accuracy: 0.8386 - val_loss: 0.0127 - val_accuracy: 0.9945\n",
      "Epoch 194/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0412 - accuracy: 0.8724 - val_loss: 0.0153 - val_accuracy: 0.8271\n",
      "Epoch 195/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0432 - accuracy: 0.8421 - val_loss: 0.0160 - val_accuracy: 0.9959\n",
      "Epoch 196/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0439 - accuracy: 0.8623 - val_loss: 0.0081 - val_accuracy: 0.9972\n",
      "Epoch 197/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0425 - accuracy: 0.8522 - val_loss: 0.0138 - val_accuracy: 0.9945\n",
      "Epoch 198/200\n",
      "53/53 [==============================] - 1s 18ms/step - loss: 0.0420 - accuracy: 0.8593 - val_loss: 0.0128 - val_accuracy: 0.9945\n",
      "Epoch 199/200\n",
      "53/53 [==============================] - 1s 19ms/step - loss: 0.0427 - accuracy: 0.8463 - val_loss: 0.0127 - val_accuracy: 0.9945\n",
      "Epoch 200/200\n",
      "53/53 [==============================] - 1s 20ms/step - loss: 0.0404 - accuracy: 0.8528 - val_loss: 0.0084 - val_accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=200, batch_size=32,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/浏览器下载/EDGE下载/LSTM_part1/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "model1 = load_model('D:/浏览器下载/EDGE下载/LSTM_part1/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.81890553,  0.85563344],\n",
       "       [ 0.81912917,  0.85554785],\n",
       "       [-0.70237076, -0.405404  ],\n",
       "       ...,\n",
       "       [ 0.82078046,  0.8542834 ],\n",
       "       [ 0.81997925,  0.85518163],\n",
       "       [ 0.81981987,  0.8552646 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(x_test[2:3].shape)\n",
    "# print(x_test[2:3])\n",
    "result = model1.predict(x_test)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(723, 2)\n",
      "[[679955.25 419831.38]\n",
      " [679955.25 419831.34]\n",
      " [679879.4  419461.56]\n",
      " ...\n",
      " [679955.3  419830.97]\n",
      " [679955.3  419831.22]\n",
      " [679955.3  419831.25]]\n"
     ]
    }
   ],
   "source": [
    "# # 设置打印选项，精度为3位小数\n",
    "# np.set_printoptions(precision=5, suppress=True)\n",
    "\n",
    "res_df = sc.inverse_transform(result)\n",
    "# res_df.reshape(new_df.shape[0],5,1)\n",
    "res_df\n",
    "print(res_df.shape)\n",
    "print(res_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413 419832.253 ]\n",
      " [679955.8419 419832.2448]\n",
      " [679878.8793 419458.8907]\n",
      " ...\n",
      " [679955.8474 419832.1637]\n",
      " [679955.844  419832.2116]\n",
      " [679955.8437 419832.2183]]\n",
      "(723, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test=y_test.reshape (723, 2)  #需要改的地方\n",
    "# y_test_actual=sc.inverse_transform(y_test[2:3])\n",
    "y_test_actual=sc.inverse_transform(y_test)\n",
    "print(y_test_actual)\n",
    "print(y_test_actual.shape)\n",
    "# for i in range(len(result)):\n",
    "#     plt.scatter(result[0][i],result[1][i],c='r')\n",
    "#     plt.scatter(y_test[0][i],y_test[1][i],c='g')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制预测值和实际值\n",
    "\n",
    "predicted_df = pd.DataFrame(data=res_df[0:,0:],index=[i for i in range(res_df.shape[0])],columns=['f'+str(i) for i in range(res_df.shape[1])])\n",
    "\n",
    "actual_df = pd.DataFrame(data=y_test_actual[0:,0:],index=[i for i in range(y_test_actual.shape[0])],columns=['f'+str(i) for i in range(y_test_actual.shape[1])])\n",
    "\n",
    "# for i in range(len(res_df)):\n",
    "# #   print(i)\n",
    "plt.scatter(x=predicted_df['f0'],y=predicted_df['f1'],c='r',s=0.1,alpha=0.5)\n",
    "plt.scatter(x=actual_df['f0'],y=actual_df['f1'],c='b',s=0.1,alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4.950070604742225\n",
      "MAE: 1.2429926694304145\n",
      "相关系数为： 0.9597269629903625\n",
      "R^2: 0.9997485417391596\n",
      "Correlation coefficient: 0.9597269629903625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# # 定义真实定位数据和预测数据\n",
    "# true_pos = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "# pred_pos = np.array([[0.5, 1.5], [3.2, 3.9], [4.9, 6.2]])\n",
    "\n",
    "# 计算均方误差\n",
    "mse = mean_squared_error(actual_df, predicted_df)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "# 计算平均绝对误差\n",
    "mae = mean_absolute_error(actual_df, predicted_df)\n",
    "print(\"MAE:\", mae)\n",
    "\n",
    "# 计算相关系数矩阵\n",
    "corr_matrix = np.corrcoef(actual_df.T, predicted_df.T)\n",
    "corr_coefficient = corr_matrix[0, 1] # 取出相关系数值\n",
    "print(\"相关系数为：\", corr_coefficient) # 打印相关系数\n",
    "# 计算决定系数\n",
    "r2 = r2_score(actual_df, predicted_df)\n",
    "print(\"R^2:\", r2)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 将实际值和预测值分别存储在矩阵中\n",
    "actual_matrix = np.array(actual_df)\n",
    "predicted_matrix = np.array(predicted_df)\n",
    "correlation_matrix = np.corrcoef(actual_matrix, predicted_matrix, rowvar=False) # 计算相关系数（Pearson相关系数）\n",
    "correlation_coefficient = correlation_matrix[0, 1] # 提取相关系数矩阵中的相关系数\n",
    "print(\"Correlation coefficient:\", correlation_coefficient) # 打印相关系数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[679955.8413  419832.253   679955.25    419831.375  ]\n",
      " [679955.8419  419832.2448  679955.25    419831.34375]\n",
      " [679878.8793  419458.8907  679879.375   419461.5625 ]\n",
      " ...\n",
      " [679955.8474  419832.1637  679955.3125  419830.96875]\n",
      " [679955.844   419832.2116  679955.3125  419831.21875]\n",
      " [679955.8437  419832.2183  679955.3125  419831.25   ]]\n"
     ]
    }
   ],
   "source": [
    " #合并两个矩阵\n",
    "merged_matrix = np.concatenate((y_test_actual, res_df), axis=1)#真实,预测\n",
    "\n",
    "print(merged_matrix) # 输出合并后矩阵的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.05854603  1.07807083  2.71739466  1.18507406  2.5934589   1.88134743\n",
      "  9.93505614  2.15186351  1.40529278  0.63132233  4.9916182   2.80879564\n",
      "  1.40529278  1.33669107  0.67451556  1.58090992  2.3987983   0.57776262\n",
      "  0.37495185  0.55332526  2.62422119  1.3244698   1.76189223  1.79709139\n",
      "  2.43187744  2.76088744  1.13203026  4.64103202  2.68577957  2.77819596\n",
      "  0.68151729  0.60889581  4.23974116  1.8639372   0.76015412  4.60052663\n",
      "  2.83985546  0.40386874  6.93469904  2.50124456  0.70523445  3.53207833\n",
      "  0.64137403  1.4185787   1.90877697  3.14974042  4.11592398  5.55054506\n",
      "  2.77819596  0.83901628  1.23002374  2.77819596  0.28908518  3.44949612\n",
      "  1.60672476  1.38411274  3.65920177  4.7279718   0.42623522  0.84865789\n",
      "  2.7318031   1.31061641  3.48680538  0.52609082  1.38475819  0.7824677\n",
      "  1.03996038 10.71912131  0.87740099  0.57809162  2.50124456  0.98633061\n",
      "  2.68577957  2.71988553  2.68577957  2.84762899  1.14788077  2.8656092\n",
      "  1.01529521  2.6146637   1.72904379  1.05762865  0.24845289  1.19177952\n",
      "  2.77819596  1.88426863  0.75372367 14.10666295  1.79156825  0.44602893\n",
      "  0.39256318  2.52343001  1.46153378  2.95822424  1.23564578  2.82725228\n",
      "  0.93998652  1.04420501  2.53197014  0.63441609  2.02614847  0.83034362\n",
      "  1.05203875  1.12919708  4.35938884  1.61010615  1.25793104  0.5281961\n",
      "  0.53626453  0.72351225  1.54901516  2.27213729  1.33332264  1.82560524\n",
      "  0.94846148  2.76632871  1.04278395  2.15186351  4.77017095  2.51346318\n",
      " 15.7439532   2.21540169 22.76745114  0.24753166  9.66362744  2.42410225\n",
      "  0.7875894   2.8595748   1.04650125  2.77819596  0.83333439  1.12188122\n",
      " 18.62620561  0.58261104  2.4267823   0.88655787  1.93728047  0.6075133\n",
      "  1.0663561   2.02556534  0.65631046  0.96491998  0.38188865  2.49627749\n",
      "  0.57143795  1.79894476  2.34492733 19.09739532  0.4338194   2.86318659\n",
      "  0.09160267  2.68577957  2.68577957  2.99527809  1.435666    1.95723167\n",
      "  2.56957749  0.99671547  4.43326028  0.72073676  2.79723438  2.80374911\n",
      "  0.50158207  1.04929865  3.62042516  2.14085342  0.65559989  0.38827311\n",
      "  2.42717238  1.28777225  2.39802347  1.79836616  1.81575947  2.83985546\n",
      "  0.50258162  0.54888488  2.39802347  1.61860646  0.80906393  1.06042113\n",
      "  1.064531    2.16133384  2.8485122   2.42884862  0.95066497  0.37898345\n",
      "  4.2516689   1.31417408  0.82188211  0.4328676   0.71189525  4.40842601\n",
      "  0.81043488  1.80248422  0.68434427  1.14938019  0.34792564  2.62621316\n",
      "  2.18258577  0.58050884  1.50237941  1.06767101  1.06503823  1.61860646\n",
      "  0.97044477  6.25726581 18.6414278   1.35013934  0.58522161  1.03295499\n",
      "  4.13949999  2.74738046  2.84904666  0.50860202  2.47888354  2.83985546\n",
      " 13.060143    2.05979201  1.07441707  2.3579055   2.63701708  1.28658954\n",
      "  1.10496183  1.41131271  2.30561665  4.51670245  0.34410843  2.81671214\n",
      "  1.18421145  0.67780272  2.81787279  0.4475494   0.97644626  2.77819596\n",
      "  1.49652076  2.7122617   1.03814362  4.23978945  2.11335441  2.71338642\n",
      "  3.93186291  0.31855161  1.06095156  2.2748388   1.3113671   1.21445694\n",
      "  1.05010058  0.62442679  1.76940624  1.82610622  2.86842586  1.98958416\n",
      "  0.26881313  4.02293576  2.70683615  0.56578874  1.93641283  0.97843652\n",
      "  0.9506463   1.36214002  2.83985546 13.08777732  2.86956231  2.47532391\n",
      "  2.15186351  1.0628705   1.58778212  1.49544766  2.29422014  1.61531625\n",
      "  0.4559936   2.56202402  2.61173971 12.61003877  1.20365195  1.13407975\n",
      "  1.21234351  2.88554484  2.58162035  0.55887459  0.69356205  2.51205787\n",
      "  2.12115667  2.52097129  1.0624469   1.435666    1.38630225  2.30561665\n",
      "  0.79166823  0.95211634  1.12335609  0.41201874  1.50587348  2.11988123\n",
      "  0.64731495  1.48560008  4.1912298   1.04336102  2.18258577  0.79350493\n",
      "  0.96258374  1.93728047  1.49652076  1.01835609  0.1790417   2.4205157\n",
      "  0.56157416  5.50004473  2.5934589   0.96893839  1.41075765  1.21288227\n",
      "  1.59468989  1.74280613  2.2748388   1.80248422  1.28507709  0.71772441\n",
      "  1.06194835  1.9529922   0.2608547   1.29444114  2.55949994  1.04885088\n",
      "  0.60181967  1.14372422  0.9833795   0.24290002  3.93369637  2.41549608\n",
      "  1.1473923   2.83339088  0.2771839   1.04047676  2.50124456  0.94597114\n",
      " 16.79870866  1.71495925  2.36720946  0.55414497  1.04107327  1.46941622\n",
      "  0.57055283  5.71413753  1.43118167  0.67883279  2.28494971  1.05705351\n",
      "  1.30363369  0.95221437  2.29595988  0.25658388  3.98226253  0.76318069\n",
      "  0.82719772  0.96737911  1.04591425  3.49029433  2.83985546  0.94535583\n",
      "  0.91225932  0.61082853  0.58641525  2.5934589   0.61609067  4.4397845\n",
      "  6.89246563  2.2614981   2.77147695  2.11276991  2.22853154  0.97533461\n",
      "  0.59592068  2.75839123  3.90934708  2.85663924  2.17787097  1.07091302\n",
      "  1.4651394   0.68415725  3.97234168  1.16498104  2.46634044  0.97051923\n",
      "  0.90941156  1.21500133  2.38748038  2.77819596  1.74110579  0.55074468\n",
      "  1.27881825  1.49618466  2.68577957  0.24416538 10.13058813  1.52699797\n",
      "  1.06555871  1.44643042  2.2133228   1.02447058  1.2002048   0.32983058\n",
      "  2.71084217  1.12589864  0.54652355  0.45683615  0.95649719  1.15137468\n",
      "  1.95750654  1.48139573  1.00540601  2.62475837  0.67495551  1.99849772\n",
      "  0.73832148  0.25563945  1.03248898  0.26999802  2.72252988  2.96026318\n",
      "  1.1639793   2.86206238  0.37055174  1.18729477  1.35989487  2.48956346\n",
      "  1.46664165  1.37495886  0.46361459  1.02686412  0.25736173  2.22545197\n",
      "  5.68792143  0.53532177  2.87069885  2.81928745  1.06642919  0.80977109\n",
      "  0.5644768   0.86177676  0.59620845  6.77908559  3.29456956  2.5934589\n",
      "  0.82692543  3.91864095  2.85805782 11.56020327  2.24047657  0.27730796\n",
      "  1.71044704  1.04416285  0.97237831  1.11108182  2.78195937  1.13034442\n",
      "  2.53197014  0.83550649  2.83985546  0.35962416  0.89819924  1.71044704\n",
      "  1.31081924  2.62422119  1.24360293  1.04690524  3.98251059  0.24693793\n",
      "  0.95649719  4.41000562  0.77991023  0.95515426  1.89459138  2.08475688\n",
      "  1.22398082  2.74738046  0.92373494  2.83992577  2.16957117  1.75573222\n",
      "  0.52443063  2.77819596  2.87196979  1.63713668  1.21391794  0.97282491\n",
      "  7.32237313  0.69104379  1.02887815  0.88100394  0.58363241  1.07451122\n",
      "  1.22009274  0.24961901  1.06909735  2.244074    6.44815818  1.04640969\n",
      "  2.60926716  0.92193598  2.02913567  2.15769241  0.2562147   0.23223872\n",
      "  4.78582073  0.53853795  2.46744907  1.23280067  2.83985546  2.42543537\n",
      "  0.66580701  3.92829274  0.8324278   2.62088787  6.62006809  0.25170004\n",
      "  3.56293045  2.02913567  0.53116801  0.5753622   1.79778758  1.08225673\n",
      "  3.5886017   0.98196496  1.51944196  2.32399843  8.31941284  0.66024263\n",
      "  5.40283677  0.50637877  2.5235271   4.4030658   2.65499488  1.16027856\n",
      "  2.45968449  2.71657488  0.53084781  1.0614499   2.42110677  6.21997666\n",
      "  0.26897948  2.80773448  1.36053503  3.57581351  2.67359873  0.94902321\n",
      "  2.5934589   2.45968449  1.12775036  0.77177176  2.83985546  0.98117624\n",
      "  0.99064941  4.49380205  0.85168417  2.65499488  2.18258577  2.87069885\n",
      "  9.08575708  2.57353269  1.03873629  1.99849772  2.31230898  1.06294555\n",
      "  1.9428398   2.05979201  0.82645544  2.05426851  0.99741204  0.21431589\n",
      "  7.57497843  1.68697099  2.5934589   0.27130911  0.50626994  0.97076382\n",
      "  0.25859391  0.25292491  3.51654707  3.36008929  5.1409149   2.42884862\n",
      "  0.94432857  2.62422119  3.93831991  2.43441664  1.2424966   1.2677881\n",
      "  2.47910325  0.73113218  2.87069885  0.90364956  0.55598707  1.96991304\n",
      "  0.28835917  5.32705153  4.99845501  3.42303915  1.69371837  2.19947966\n",
      "  0.53802543  2.62986813  2.34820708  1.54316553  1.72926986  2.71657488\n",
      "  0.28605343  1.19231617  0.83313675  0.98707042  1.57764743  1.23402279\n",
      "  2.36720946  2.32181463  0.30494231  0.24319778  0.59354044  1.32030834\n",
      "  1.57602122  1.22362942  2.61067972  1.38777202  2.74738046  1.12669213\n",
      "  1.29432256  2.37793922  2.57212224  1.0493212   2.36720946  0.97952414\n",
      "  2.02498222  1.1639793   1.607718    4.46806815  2.69523835  0.9600926\n",
      "  5.40582588  1.01959847  1.44193018  7.81214479  0.96357722  3.01882178\n",
      "  2.2748388   1.06485797  1.88542967  0.98661417  1.07999683  5.39645307\n",
      "  0.79644935  1.07451122  1.08175435  2.61325068  1.7717852   1.47835206\n",
      "  1.51251531  2.77819596  1.0308157   1.64919611  2.83985546  1.03128107\n",
      "  0.79401705  2.5934589   2.70036351  1.04147086  2.83985546  0.66964949\n",
      "  1.25407311  2.38858374  1.03476157  0.52263831  0.9501116   1.00789795\n",
      "  4.21862504  0.73049904  1.05295799  2.50124456  1.4405042   0.91893195\n",
      "  0.25622818  1.55015751  1.1895441   3.98416953  1.52965316  2.69660036\n",
      "  0.96211184  0.67668339  0.86956417  1.6034589   1.06416161  0.94723384\n",
      "  2.71657488  1.96787901  2.74738046  0.3536509   0.83648671 14.12143466\n",
      "  1.33461223  1.06094076  2.05304373  3.5232806   1.57451899  3.00097123\n",
      "  1.31441979  0.54052279  0.97157231  2.57108558  4.73096569  1.45861377\n",
      "  2.87069885  2.45012402  2.53197014  2.81282159  0.27065689  2.83985546\n",
      "  2.2748388   1.1656442   0.56271869  2.61315831  0.94353854  0.58806564\n",
      "  1.30920721  1.12616312  1.10443575]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# 计算每行数据中两个点之间的欧式距离\n",
    "distances = np.linalg.norm(merged_matrix[:, :2] - merged_matrix[:, 2:], axis=1)\n",
    "print(distances)\n",
    "np.savetxt('distances.txt', distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.用库\n",
    "2.分析误差\n",
    "3.v2x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
